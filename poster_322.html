

<!DOCTYPE html>
<html lang="en">
<head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8"/>
    <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script
            src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
            crossorigin="anonymous"
    ></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
            integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
            integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
            crossorigin="anonymous"></script>
            <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=Gantari:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Library libs_ext --> 
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin="anonymous" referrerpolicy="no-referrer" />


    <!--    Internal Libs -->
    <script src="static/js/data/api.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY="
          crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
            href="static/css/Lato.css"
            rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet"/>
    <link
            href="static/css/Cuprum.css"
            rel="stylesheet"
    />
    <link rel="stylesheet" href="static/css/main.css"/>
<!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css"/>
    <link rel="stylesheet" href="static/css/lazy_load.css"/>
    <link rel="stylesheet" href="static/css/typeahead.css"/>

    <title>ISMIR 2024</title>
    
<meta name="citation_title" content=""/>

<meta name="citation_publication_date" content="May 2024"/>
<meta name="citation_conference_title"
      content="Ismir 2024"/>
<meta name="citation_inbook_title" content="Proceedings of the 25th International Society for Music Information Retrieval"/>
<meta name="citation_abstract" content=""/>

<meta name="citation_pdf_url" content=""/>


</head>

<body>
<!-- NAV -->

<nav
        class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
        id="main-nav"
>
    <div class="container">
        <a class="navbar-brand" href="index.html">
            <img
                    class="logo" src="static/images/ismir24_logo.svg"
                    height="auto"
            width="95px"
            />
        </a>
        
        <button
                class="navbar-toggler"
                type="button"
                data-toggle="collapse"
                data-target="#navbarNav"
                aria-controls="navbarNav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div
                class="collapse navbar-collapse text-right flex-grow-1"
                id="navbarNav"
        >
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="index.html">Schedule</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="papers.html">Papers</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="tutorials.html">Tutorials</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="lbds.html">LBDs</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="industry.html">Industry</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>



<!-- User Overrides -->
 

<div class="container">
    <!-- Tabs -->
    <div class="tabs">
         
    </div>
    <!-- Content -->
    <div class="content">
        
<div class="pp-card m-3" style="background-color: #fff">
    <div class="card-header" style="background-color: rgba(0,0,0,0);">
        <h2 class="card-title main-title text-left" style="color: #4383EC">
            RNBert: Fine-Tuning a Masked Language Model for Roman Numeral Analysis
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-left">
            
            <a href="papers.html?filter=authors&search=Sailor, Malcolm*"
               class="text-muted"
            >Sailor, Malcolm*</a
            >
            
        </h3>
        
        <div class="btn-group ml-3 mb-3">
          <a href="https://ismir2024.slack.com/archives/C07UHCXAFE2" class="btn btn-primary" style="background-color: #2294e0;"><svg style="display: inline-block; width: 23px;" version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="75 75 150 150" style="enable-background:new 0 0 270 270;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
</style>
<g>
	<g>
		<path class="st0" d="M99.4,151.2c0,7.1-5.8,12.9-12.9,12.9s-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h12.9V151.2z"/>
		<path class="st0" d="M105.9,151.2c0-7.1,5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v32.3c0,7.1-5.8,12.9-12.9,12.9
			s-12.9-5.8-12.9-12.9C105.9,183.5,105.9,151.2,105.9,151.2z"/>
	</g>
	<g>
		<path class="st0" d="M118.8,99.4c-7.1,0-12.9-5.8-12.9-12.9s5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v12.9H118.8z"/>
		<path class="st0" d="M118.8,105.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9H86.5c-7.1,0-12.9-5.8-12.9-12.9
			s5.8-12.9,12.9-12.9C86.5,105.9,118.8,105.9,118.8,105.9z"/>
	</g>
	<g>
		<path class="st0" d="M170.6,118.8c0-7.1,5.8-12.9,12.9-12.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9h-12.9V118.8z"/>
		<path class="st0" d="M164.1,118.8c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9V86.5c0-7.1,5.8-12.9,12.9-12.9
			c7.1,0,12.9,5.8,12.9,12.9V118.8z"/>
	</g>
	<g>
		<path class="st0" d="M151.2,170.6c7.1,0,12.9,5.8,12.9,12.9c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9v-12.9H151.2z"/>
		<path class="st0" d="M151.2,164.1c-7.1,0-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h32.3c7.1,0,12.9,5.8,12.9,12.9
			c0,7.1-5.8,12.9-12.9,12.9H151.2z"/>
	</g>
</g>
</svg> p5-17-rnbert-fine-tuning</a>
        </div>
        
        <p class="card-text text-left">
            <span class="">Keywords:</span>
            
            <a
                    href="papers.html?filter=keywords&search=Computational musicology; Knowledge-driven approaches to MIR -&gt; computational music theory and musicology; MIR fundamentals and methodology -&gt; symbolic music processing; MIR tasks -&gt; automatic classification; Musical features and properties -&gt; harmony, chords and tonality"
                    class="text-secondary text-decoration-none"
            >Computational musicology; Knowledge-driven approaches to MIR -&gt; computational music theory and musicology; MIR fundamentals and methodology -&gt; symbolic music processing; MIR tasks -&gt; automatic classification; Musical features and properties -&gt; harmony, chords and tonality</a
            >,
            
            <a
                    href="papers.html?filter=keywords&search=Knowledge-driven approaches to MIR -&gt; machine learning/artificial intelligence for music"
                    class="text-secondary text-decoration-none"
            >Knowledge-driven approaches to MIR -&gt; machine learning/artificial intelligence for music</a
            >
            
        </p>
    </div>

</div>

<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <span class="font-weight-bold">Abstract:</span>
                <p>Music is plentiful, but labeled data for music theory tasks like roman numeral analysis is scarce. Self-supervised pretraining on unlabeled data is therefore a promising means of improving performance on these tasks, especially because, during pretraining, a model may be expected to acquire latent representations of musical abstractions like keys and chords. However, existing deep learning models for roman numeral analysis have not used pretraining, instead training from scratch on labeled data, while conversely, pretrained models for music understanding have generally been applied to sequence-level tasks not involving explicit music theory, like composer or genre classification. In contrast, this paper applies pretraining methods to a music theory task by fine-tuning a masked language model, MusicBERT, for roman numeral analysis. We apply token classification to predict labels for each note, then aggregate the predictions of simultaneous notes to obtain a single label at each time step. Conditioning the chord predictions on key predictions gives more coherent labels. The resulting model outperforms previous roman numeral analysis models by a substantial margin.</p>
            </div>
        </div>
        <p></p>
    </div>
</div>


  
  <div class="text-center">
    <ul class="nav nav-tabs" id="posterTabs" role="tablist">
      <li class="nav-item" role="presentation">
        <a class="nav-link active" id="paper-tab" data-toggle="tab" href="#paper" role="tab" aria-controls="paper" aria-selected="true">Paper</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="poster-tab" data-toggle="tab" href="#poster" role="tab" aria-controls="poster" aria-selected="false">Poster</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="video-tab" data-toggle="tab" href="#video" role="tab" aria-controls="video" aria-selected="false">Video</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="Reviews-tab" data-toggle="tab" href="#Reviews" role="tab" aria-controls="Reviews" aria-selected="false">Reviews</a>
      </li>
    </ul>
  </div>
  

  <div class="tab-content" id="posterTabsContent">
    <div class="tab-pane fade show active" id="paper" role="tabpanel" aria-labelledby="paper-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/1Gqyk2QoOrzJXOPd_LBgchAsnBDJxG6cz/preview?usp=drive_link" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="poster" role="tabpanel" aria-labelledby="poster-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/1shpkSE2PSIr-u-vcBxTryredYcCwPBRu/preview?usp=drive_link" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="video" role="tabpanel" aria-labelledby="video-tab">
      
      <div class="text-center">
        <div class="embed-responsive embed-responsive-16by9">
          <iframe class="embed-responsive-item"           
                  src="https://drive.google.com/file/d/101uolZhDyW2dpOhoPqlgfgy_uM_kyBIu/preview?usp=drive_link" 
                  frameborder="0" 
                  allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" 
                  allowfullscreen></iframe>
        </div>
      </div>
      
    </div>
    <div class="tab-pane fade" id="Reviews" role="tabpanel" aria-labelledby="Reviews-tab">
      <div class="pp-card m-3">
        <div class="card-body">
          <h5 class="card-title">
            Reviews
          </h5>
          <div class="card-text">
            
            <div> 
                <b> Meta Review </b> 
                <p> <p>All of the reviwers are concerned about the lack of detail and evaluation of the fine-tuning process. We encourage the authors to expand this is any revision of the paper.</p></p>
              </div>
              <hr/>
        
            <div>
                <b> Review 1 </b>
                <p class="card-text"><p>The idea of this paper is simple: using a pre-trained model for symbolic music, MusicBERT, to improve the performance for roman numeral analysis. Although it achieves better performances than previous approaches, I am looking for a in-depth discussion on the choice of MusicBERT: why it instead of other similar models like MidiBERT-Piano and others? This is an essential question that the authors need to answer in the camera-ready version (if it comes to that) and even better, if authors conduct a comparative study on how the choice of different pre-trained models (including MusicBERT) affects the performance of roman numeral analysis. Althought the latter may require extra experiments that won't make it to this paper, I strongly suggest the author at least present a reasonable review on pre-trained models for symbolic music and the choice of MusicBERT. Without it, this work won't be considered a solid contribution to the community.</p>
<p>Other than that, this paper is generally easy to follow but lacks polishing in some occasions. For example, the formatting of the references is bad, and the caption of Table 1 is overly short without meaningful descriptions, hence lacking a period in the end. Also, a model diagram illustrating its training and inference will be helpful, especially on the post-processing part in Section 3.7, which I find difficult to follow. Although it is nice to open-source the code, as indicated in Footnote 1, the authors should be more discreet about anonymity as the username embedded in the github URL will easily give away the identity of this submission. There are also grammatical errors shown as follow. </p>
<p>Line 85: [14] add -&gt; [14] adds
Line 103: including by -&gt; including</p>
<p>Overall, I will give weak accept for this paper, on the condition that (1) the authors work on the explanation of why MusicBERT is chosen and (2) polish its content further to make it a competent ISMIR publication.  </p></p>
              </div>
            </div>
            <hr/>

            <div> 
                <b> Review 2 </b>
                <p>Overall, this is a very good, precisely written, scientifically sound, and interesting paper. The general approach of finetuning for token classification itself is certainly not the most novel idea. However, the authors carefully consider and describe all parts involved to achieve that, from the dataset, preprocessing, and tokenization to postprocessing and other interesting tweaks (e.g. key conditioning). I was pleased to have each doubt that arose immediately answered in the paper through the side-experiments mentioned and ablations that were presented. Each part of the methodology is precisely described and design choices are justified from both a scientific and music-theoretic perspective. Results are also carefully and interestingly described from these lenses.</p>
<p>The writing is clear and precise and the paper is organized well. It is perhaps slightly unusual to see the experimental setup subsections in this order (usually I'd expect to move from model to data), but it works well and, importantly, there are no redundancies or ambiguities.</p>
<p>It would have been interesting to see a bit more work (and perhaps detail in the paper) in the choice of finetuning. There isn't adequate justification about why the first 9 layers of BERT are frozen specifically. It would have been interesting to experiment with different layer freezing, and even parameter- and resource-efficient fine-tuning methods like LoRA. All this is particularly interesting because of existing indications about how different the information between transformers' layers can be. In "Comparative Layer-Wise Analysis of Self-Supervised Speech Models” by Pasad et al., for example, layer similarity of voice models with phonemes and words is computed, yielding interesting results about the "location" of relevant features. It's not trivial to adapt this framework to symbolic music and RN analysis, but it would certainly be interesting.</p>
<p>It would have been nice (and it's still possible for the camera-ready) to acknowledge some compute-related information of your experiments, such as the finetuning and inference cost, in relation to existing work (at least through the parameter counts).</p>
<p>The citations are not well formatted and would need to be fixed for the camera ready. Please only include arxiv/zenodo versions if the paper isn't published already in a venue. Use consistent conference names and abbreviations (International Society [...] (ISMIR) Conference vs ISMIR) and conference locations and years. If you decide to provide links, please do so consistently when they are available and from appropriate sources.</p>
<p>Minor comments:
- l48: fine tune; l51: fine-tune
- table 1: maybe some thousands separators on the numbers
- table 2: somehow need to shorten the width
- l291-292: is "in particular" or "solely on Classical" more accurate?
- l341-347: it's understandable after a slow read, but would be better to try to split the sentence</p></p>
              </div>
              <hr/>


            <div> 
                <b> Review 3 </b>
                <p>This paper introduces a new approach to Roman numeral analysis that outperforms previous state-of-the-art models by leveraging pretraining on a Bert-like architecture.</p>
<p>The paper is well-written, and the results are highly promising, while also addressesing important questions regarding automatic Roman numeral analysis. Namely, the authors address the issue of potential multiple valid interpretations of a given segment or analysis.</p>
<p>However, there are several areas that would require minor corrections and refinement:</p>
<ol>
<li>
<p>Missing Publication Years in References: A very important point is that, all references lack the publication year, which is essential for proper citation and a high standard of an academic proceedings paper.</p>
</li>
<li>
<p>Inconsistency in References: A more minor point is the presentation of publishing venues for proceedings which are abbreviated or in a couple of case missing completely, for example pay attention to "in ISMIR": -&gt; should be "in Proceedings of the International Society for Music Information Retrieval Conference (ISMIR)" and likewise for others. In summary, it is highly suggested to the authors to fix the references section. </p>
</li>
<li>
<p>Caution against Overstated Claims: Strong claims should be tempered. For instance, the assertion in footnote 8 implying the potential incorrectness of a human annotator's analysis should be approached with caution. Multiple valid interpretations can exist for a segment or Roman numeral, as highlighted in Section 4.2. Hence, it's advisable for the authors to avoid absolute statements regarding the absolute correctness of any single analysis.</p>
</li>
<li>
<p>Standardization of Terminology: The capitalization of "Roman numeral" throughout the text varies. For consistency, it should be "Roman numeral," with "Roman" capitalized as it serves as an adjective referencing a place of origin.</p>
</li>
<li>
<p>Reevaluation of Key Prediction Triviality: The claim that predicting the key is trivial warrants reevaluation. While the paper suggests high accuracy in key prediction, it's crucial to consider the broader context. Many existing approaches, such as AugmentedNet, ChordGNN, and PKSpell, do not achieve near-perfect accuracy in predicting local keys or key signatures. Supporting this claim with evidence from publications demonstrating similar high accuracies would strengthen its validity. Alternatively, softening the claim to reflect the complexity and challenges associated with key prediction would be more prudent.</p>
</li>
</ol>
<p>Addressing these points will enhance the clarity, strength, and credibility of the paper.</p></p>
              </div>
              <hr/>

            
            <div> 
            <b> Author description of changes: </b>
            <p>I respond to the main reviewer comments below. The paper has been updated to address issues of formatting, grammar, etc., without further comment here.</p>
<h1>Reviewer 1</h1>
<blockquote>
<p>I am looking for a in-depth discussion on the choice of MusicBERT</p>
</blockquote>
<p>I added an explanation of why I chose to use MusicBERT. I agree that a comparative evaluation of MusicBERT with other models would be useful, but that will await future work. In any case, the main contribution of this paper is the general approach of using a pre-trained masked language model for token-level music theory tasks, which to our knowledge has not previously been applied to Roman numeral analysis or any similar task.</p>
<blockquote>
<p>a model diagram illustrating its training and inference will be helpful</p>
</blockquote>
<p>Unfortunately we do not have space to add this while remaining within the space constraints of an ISMIR paper.</p>
<h1>Reviewer 2</h1>
<blockquote>
<p>There isn't adequate justification about why the first 9 layers of BERT are frozen specifically. It would have been interesting to experiment with different layer freezing, and even parameter- and resource-efficient fine-tuning methods like LoRA.</p>
</blockquote>
<p>I now state how and why I chose to freeze the first 9 layers. I agree that LoRA is worth trying, but that will await future work.</p>
<blockquote>
<p>acknowledge some compute-related information of your experiments, such as the finetuning and inference cost, in relation to existing work (at least through the parameter counts).</p>
</blockquote>
<p>Thank you for mentioning this oversight. I added parameter counts.</p>
<h1>Reviewer 3</h1>
<blockquote>
<p>The claim that predicting the key is trivial warrants reevaluation.</p>
</blockquote>
<p>The reviewer may have misunderstood one small claim. Key prediction is not trivial. What I suggest is "trivial" is the task of predicting a spelled key (like "Db major") given</p>
<ul>
<li>an unspelled key (like "1 major" for a major key with tonic pc 1), and</li>
<li>spelled pitch inputs (like Db5 and Ab5) rather than unspelled inputs (like MIDInums 61 and 68).</li>
</ul>
<p>I revised the passage in question to clarify it with examples.</p></p>
            </div>
                   
          </div>
                    
    
        </div>
      </div>
    
  </div>
  





  <script>
  document.addEventListener('DOMContentLoaded', function() {
    console.log(JSON.stringify("{&#39;id&#39;: &#39;322&#39;, &#39;session&#39;: &#39;5&#39;, &#39;position&#39;: &#39;18&#39;, &#39;forum&#39;: &#39;322&#39;, &#39;pic_id&#39;: &#39;https://drive.google.com/file/d/1wLkwNpEi0tli-WbJLSHEaU8B3vOOW9zn/view?usp=drive_link&#39;, &#39;content&#39;: {&#39;title&#39;: &#39;RNBert: Fine-Tuning a Masked Language Model for Roman Numeral Analysis&#39;, &#39;paper_presentation&#39;: &#39;San Francisco&#39;, &#39;long_presentation&#39;: &#39;FALSE&#39;, &#39;authors&#39;: [&#39;Sailor, Malcolm*&#39;], &#39;authors_and_affil&#39;: [&#39;Malcolm Sailor (Yale University)*&#39;], &#39;keywords&#39;: [&#39;Computational musicology; Knowledge-driven approaches to MIR -&gt; computational music theory and musicology; MIR fundamentals and methodology -&gt; symbolic music processing; MIR tasks -&gt; automatic classification; Musical features and properties -&gt; harmony, chords and tonality&#39;, &#39;Knowledge-driven approaches to MIR -&gt; machine learning/artificial intelligence for music&#39;], &#39;abstract&#39;: &#39;Music is plentiful, but labeled data for music theory tasks like roman numeral analysis is scarce. Self-supervised pretraining on unlabeled data is therefore a promising means of improving performance on these tasks, especially because, during pretraining, a model may be expected to acquire latent representations of musical abstractions like keys and chords. However, existing deep learning models for roman numeral analysis have not used pretraining, instead training from scratch on labeled data, while conversely, pretrained models for music understanding have generally been applied to sequence-level tasks not involving explicit music theory, like composer or genre classification. In contrast, this paper applies pretraining methods to a music theory task by fine-tuning a masked language model, MusicBERT, for roman numeral analysis. We apply token classification to predict labels for each note, then aggregate the predictions of simultaneous notes to obtain a single label at each time step. Conditioning the chord predictions on key predictions gives more coherent labels. The resulting model outperforms previous roman numeral analysis models by a substantial margin.&#39;, &#39;TLDR&#39;: &#39;Music is plentiful, but labeled data for music theory tasks like roman numeral analysis is scarce. Self-supervised pretraining on unlabeled data is therefore a promising means of improving performance on these tasks, especially because, during pretraining, a model may be expected to acquire latent representations of musical abstractions like keys and chords. However, existing deep learning models for roman numeral analysis have not used pretraining, instead training from scratch on labeled data, while conversely, pretrained models for music understanding have generally been applied to sequence-level tasks not involving explicit music theory, like composer or genre classification. In contrast, this paper applies pretraining methods to a music theory task by fine-tuning a masked language model, MusicBERT, for roman numeral analysis. We apply token classification to predict labels for each note, then aggregate the predictions of simultaneous notes to obtain a single label at each time step. Conditioning the chord predictions on key predictions gives more coherent labels. The resulting model outperforms previous roman numeral analysis models by a substantial margin.&#39;, &#39;poster_pdf&#39;: &#39;https://drive.google.com/file/d/1shpkSE2PSIr-u-vcBxTryredYcCwPBRu/view?usp=drive_link&#39;, &#39;session&#39;: [&#39;5&#39;], &#39;pdf_path&#39;: &#39;https://drive.google.com/file/d/1Gqyk2QoOrzJXOPd_LBgchAsnBDJxG6cz/view?usp=drive_link&#39;, &#39;video&#39;: &#39;https://drive.google.com/file/d/101uolZhDyW2dpOhoPqlgfgy_uM_kyBIu/view?usp=drive_link&#39;, &#39;channel_url&#39;: &#39;https://ismir2024.slack.com/archives/C07UHCXAFE2&#39;, &#39;slack_channel&#39;: &#39;p5-17-rnbert-fine-tuning&#39;, &#39;day&#39;: &#39;3&#39;, &#39;review_1&#39;: &#34;The idea of this paper is simple: using a pre-trained model for symbolic music, MusicBERT, to improve the performance for roman numeral analysis. Although it achieves better performances than previous approaches, I am looking for a in-depth discussion on the choice of MusicBERT: why it instead of other similar models like MidiBERT-Piano and others? This is an essential question that the authors need to answer in the camera-ready version (if it comes to that) and even better, if authors conduct a comparative study on how the choice of different pre-trained models (including MusicBERT) affects the performance of roman numeral analysis. Althought the latter may require extra experiments that won&#39;t make it to this paper, I strongly suggest the author at least present a reasonable review on pre-trained models for symbolic music and the choice of MusicBERT. Without it, this work won&#39;t be considered a solid contribution to the community.\n\nOther than that, this paper is generally easy to follow but lacks polishing in some occasions. For example, the formatting of the references is bad, and the caption of Table 1 is overly short without meaningful descriptions, hence lacking a period in the end. Also, a model diagram illustrating its training and inference will be helpful, especially on the post-processing part in Section 3.7, which I find difficult to follow. Although it is nice to open-source the code, as indicated in Footnote 1, the authors should be more discreet about anonymity as the username embedded in the github URL will easily give away the identity of this submission. There are also grammatical errors shown as follow. \n\nLine 85: [14] add -&gt; [14] adds\nLine 103: including by -&gt; including\n\nOverall, I will give weak accept for this paper, on the condition that (1) the authors work on the explanation of why MusicBERT is chosen and (2) polish its content further to make it a competent ISMIR publication.  &#34;, &#39;review_2&#39;: &#39;Overall, this is a very good, precisely written, scientifically sound, and interesting paper. The general approach of finetuning for token classification itself is certainly not the most novel idea. However, the authors carefully consider and describe all parts involved to achieve that, from the dataset, preprocessing, and tokenization to postprocessing and other interesting tweaks (e.g. key conditioning). I was pleased to have each doubt that arose immediately answered in the paper through the side-experiments mentioned and ablations that were presented. Each part of the methodology is precisely described and design choices are justified from both a scientific and music-theoretic perspective. Results are also carefully and interestingly described from these lenses.\n\nThe writing is clear and precise and the paper is organized well. It is perhaps slightly unusual to see the experimental setup subsections in this order (usually I\&#39;d expect to move from model to data), but it works well and, importantly, there are no redundancies or ambiguities.\n\nIt would have been interesting to see a bit more work (and perhaps detail in the paper) in the choice of finetuning. There isn\&#39;t adequate justification about why the first 9 layers of BERT are frozen specifically. It would have been interesting to experiment with different layer freezing, and even parameter- and resource-efficient fine-tuning methods like LoRA. All this is particularly interesting because of existing indications about how different the information between transformers\&#39; layers can be. In &#34;Comparative Layer-Wise Analysis of Self-Supervised Speech Models” by Pasad et al., for example, layer similarity of voice models with phonemes and words is computed, yielding interesting results about the &#34;location&#34; of relevant features. It\&#39;s not trivial to adapt this framework to symbolic music and RN analysis, but it would certainly be interesting.\n\nIt would have been nice (and it\&#39;s still possible for the camera-ready) to acknowledge some compute-related information of your experiments, such as the finetuning and inference cost, in relation to existing work (at least through the parameter counts).\n\nThe citations are not well formatted and would need to be fixed for the camera ready. Please only include arxiv/zenodo versions if the paper isn\&#39;t published already in a venue. Use consistent conference names and abbreviations (International Society [...] (ISMIR) Conference vs ISMIR) and conference locations and years. If you decide to provide links, please do so consistently when they are available and from appropriate sources.\n\nMinor comments:\n- l48: fine tune; l51: fine-tune\n- table 1: maybe some thousands separators on the numbers\n- table 2: somehow need to shorten the width\n- l291-292: is &#34;in particular&#34; or &#34;solely on Classical&#34; more accurate?\n- l341-347: it\&#39;s understandable after a slow read, but would be better to try to split the sentence&#39;, &#39;review_3&#39;: &#39;This paper introduces a new approach to Roman numeral analysis that outperforms previous state-of-the-art models by leveraging pretraining on a Bert-like architecture.\n\nThe paper is well-written, and the results are highly promising, while also addressesing important questions regarding automatic Roman numeral analysis. Namely, the authors address the issue of potential multiple valid interpretations of a given segment or analysis.\n\nHowever, there are several areas that would require minor corrections and refinement:\n\n1. Missing Publication Years in References: A very important point is that, all references lack the publication year, which is essential for proper citation and a high standard of an academic proceedings paper.\n\n2. Inconsistency in References: A more minor point is the presentation of publishing venues for proceedings which are abbreviated or in a couple of case missing completely, for example pay attention to &#34;in ISMIR&#34;: -&gt; should be &#34;in Proceedings of the International Society for Music Information Retrieval Conference (ISMIR)&#34; and likewise for others. In summary, it is highly suggested to the authors to fix the references section. \n\n3. Caution against Overstated Claims: Strong claims should be tempered. For instance, the assertion in footnote 8 implying the potential incorrectness of a human annotator\&#39;s analysis should be approached with caution. Multiple valid interpretations can exist for a segment or Roman numeral, as highlighted in Section 4.2. Hence, it\&#39;s advisable for the authors to avoid absolute statements regarding the absolute correctness of any single analysis.\n\n4. Standardization of Terminology: The capitalization of &#34;Roman numeral&#34; throughout the text varies. For consistency, it should be &#34;Roman numeral,&#34; with &#34;Roman&#34; capitalized as it serves as an adjective referencing a place of origin.\n\n5. Reevaluation of Key Prediction Triviality: The claim that predicting the key is trivial warrants reevaluation. While the paper suggests high accuracy in key prediction, it\&#39;s crucial to consider the broader context. Many existing approaches, such as AugmentedNet, ChordGNN, and PKSpell, do not achieve near-perfect accuracy in predicting local keys or key signatures. Supporting this claim with evidence from publications demonstrating similar high accuracies would strengthen its validity. Alternatively, softening the claim to reflect the complexity and challenges associated with key prediction would be more prudent.\n\nAddressing these points will enhance the clarity, strength, and credibility of the paper.&#39;, &#39;meta_review&#39;: &#39;All of the reviwers are concerned about the lack of detail and evaluation of the fine-tuning process. We encourage the authors to expand this is any revision of the paper.&#39;, &#39;author_changes&#39;: &#39;I respond to the main reviewer comments below. The paper has been updated to address issues of formatting, grammar, etc., without further comment here.\n\n# Reviewer 1\n\n&gt; I am looking for a in-depth discussion on the choice of MusicBERT\n\nI added an explanation of why I chose to use MusicBERT. I agree that a comparative evaluation of MusicBERT with other models would be useful, but that will await future work. In any case, the main contribution of this paper is the general approach of using a pre-trained masked language model for token-level music theory tasks, which to our knowledge has not previously been applied to Roman numeral analysis or any similar task.\n\n&gt; a model diagram illustrating its training and inference will be helpful\n\nUnfortunately we do not have space to add this while remaining within the space constraints of an ISMIR paper.\n\n# Reviewer 2\n\n&gt; There isn\&#39;t adequate justification about why the first 9 layers of BERT are frozen specifically. It would have been interesting to experiment with different layer freezing, and even parameter- and resource-efficient fine-tuning methods like LoRA.\n\nI now state how and why I chose to freeze the first 9 layers. I agree that LoRA is worth trying, but that will await future work.\n\n&gt; acknowledge some compute-related information of your experiments, such as the finetuning and inference cost, in relation to existing work (at least through the parameter counts).\n\nThank you for mentioning this oversight. I added parameter counts.\n\n# Reviewer 3\n\n&gt;  The claim that predicting the key is trivial warrants reevaluation.\n\nThe reviewer may have misunderstood one small claim. Key prediction is not trivial. What I suggest is &#34;trivial&#34; is the task of predicting a spelled key (like &#34;Db major&#34;) given\n\n- an unspelled key (like &#34;1 major&#34; for a major key with tonic pc 1), and\n- spelled pitch inputs (like Db5 and Ab5) rather than unspelled inputs (like MIDInums 61 and 68).\n\nI revised the passage in question to clarify it with examples.&#39;}, &#39;poster_pdf&#39;: &#39;GLTR_poster.pdf&#39;}"));
    // Ensure jQuery and Bootstrap are loaded
    if (typeof $ === 'undefined') {
      console.error('jQuery is not loaded');
      return;
    }
    
    // Initialize all tabs
    $('#posterTabs a').on('click', function (e) {
      e.preventDefault();
      $(this).tab('show');
    });
  
    // Show paper tab by default
    $('#posterTabs a[href="#paper"]').tab('show');
    MathJax.typesetPromise().then(() => {
    // modify the DOM here
        MathJax.typesetPromise();
    }).catch((err) => console.log(err.message));
  });
  </script>
  
  
    </div>
</div>



<!-- Google Analytics -->
<script
        async
        src="https://www.googletagmanager.com/gtag/js?id=UA-"
></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag("js", new Date());
  gtag("config", "UA-");
</script>

<!-- Footer -->
<footer class="footer bg-light p-4">
    <div class="container">
        <p class="float-right"><a href="#">Back to Top</a></p>
        <p class="text-center">© 2024 International Society for Music Information Retrieval</p>
    </div>
</footer>

<!-- Code for hash tags -->
<script type="text/javascript">
  $(document).ready(function () {
    if (window.location.hash !== "") {
      $(`a[href="${window.location.hash}"]`).tab("show");
    }

    $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
      const hash = $(e.target).attr("href");
      if (hash.substr(0, 1) === "#") {
        const position = $(window).scrollTop();
        window.location.replace(`#${hash.substr(1)}`);
        $(window).scrollTop(position);
      }
    });
   
  });
</script>
<!--    <script src="static/js/modules/lazyLoad.js"></script>-->

</body>
</html>