

<!DOCTYPE html>
<html lang="en">
<head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8"/>
    <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script
            src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
            crossorigin="anonymous"
    ></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
            integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
            integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
            crossorigin="anonymous"></script>
            <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=Gantari:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Library libs_ext --> 
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin="anonymous" referrerpolicy="no-referrer" />


    <!--    Internal Libs -->
    <script src="static/js/data/api.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY="
          crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
            href="static/css/Lato.css"
            rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet"/>
    <link
            href="static/css/Cuprum.css"
            rel="stylesheet"
    />
    <link rel="stylesheet" href="static/css/main.css"/>
<!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css"/>
    <link rel="stylesheet" href="static/css/lazy_load.css"/>
    <link rel="stylesheet" href="static/css/typeahead.css"/>

    <title>ISMIR 2024</title>
    
<meta name="citation_title" content=""/>

<meta name="citation_publication_date" content="May 2024"/>
<meta name="citation_conference_title"
      content="Ismir 2024"/>
<meta name="citation_inbook_title" content="Proceedings of the 25th International Society for Music Information Retrieval"/>
<meta name="citation_abstract" content=""/>

<meta name="citation_pdf_url" content=""/>


</head>

<body>
<!-- NAV -->

<nav
        class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
        id="main-nav"
>
    <div class="container">
        <a class="navbar-brand" href="index.html">
            <img
                    class="logo" src="static/images/ismir24_logo.svg"
                    height="auto"
            width="95px"
            />
        </a>
        
        <button
                class="navbar-toggler"
                type="button"
                data-toggle="collapse"
                data-target="#navbarNav"
                aria-controls="navbarNav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div
                class="collapse navbar-collapse text-right flex-grow-1"
                id="navbarNav"
        >
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="index.html">Schedule</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="papers.html">Papers</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="tutorials.html">Tutorials</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="lbds.html">LBDs</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="industry.html">Industry</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>



<!-- User Overrides -->
 

<div class="container">
    <!-- Tabs -->
    <div class="tabs">
         
    </div>
    <!-- Content -->
    <div class="content">
        
<div class="pp-card m-3" style="background-color: #fff">
    <div class="card-header" style="background-color: rgba(0,0,0,0);">
        <h2 class="card-title main-title text-left" style="color: #4383EC">
            A Contrastive Self-Supervised Learning scheme for beat tracking amenable to few-shot learning
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-left">
            
            <a href="papers.html?filter=authors&search=Gagneré, Antonin*"
               class="text-muted"
            >Gagneré, Antonin*</a
            >,
            
            <a href="papers.html?filter=authors&search= Essid, Slim"
               class="text-muted"
            > Essid, Slim</a
            >,
            
            <a href="papers.html?filter=authors&search= Peeters, Geoffroy"
               class="text-muted"
            > Peeters, Geoffroy</a
            >
            
        </h3>
        
        <div class="btn-group ml-3 mb-3">
          <a href="https://ismir2024.slack.com/archives/C07USGNN5C4" class="btn btn-primary" style="background-color: #2294e0;"><svg style="display: inline-block; width: 23px;" version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="75 75 150 150" style="enable-background:new 0 0 270 270;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
</style>
<g>
	<g>
		<path class="st0" d="M99.4,151.2c0,7.1-5.8,12.9-12.9,12.9s-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h12.9V151.2z"/>
		<path class="st0" d="M105.9,151.2c0-7.1,5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v32.3c0,7.1-5.8,12.9-12.9,12.9
			s-12.9-5.8-12.9-12.9C105.9,183.5,105.9,151.2,105.9,151.2z"/>
	</g>
	<g>
		<path class="st0" d="M118.8,99.4c-7.1,0-12.9-5.8-12.9-12.9s5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v12.9H118.8z"/>
		<path class="st0" d="M118.8,105.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9H86.5c-7.1,0-12.9-5.8-12.9-12.9
			s5.8-12.9,12.9-12.9C86.5,105.9,118.8,105.9,118.8,105.9z"/>
	</g>
	<g>
		<path class="st0" d="M170.6,118.8c0-7.1,5.8-12.9,12.9-12.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9h-12.9V118.8z"/>
		<path class="st0" d="M164.1,118.8c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9V86.5c0-7.1,5.8-12.9,12.9-12.9
			c7.1,0,12.9,5.8,12.9,12.9V118.8z"/>
	</g>
	<g>
		<path class="st0" d="M151.2,170.6c7.1,0,12.9,5.8,12.9,12.9c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9v-12.9H151.2z"/>
		<path class="st0" d="M151.2,164.1c-7.1,0-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h32.3c7.1,0,12.9,5.8,12.9,12.9
			c0,7.1-5.8,12.9-12.9,12.9H151.2z"/>
	</g>
</g>
</svg> p1-19-a-contrastive-self</a>
        </div>
        
        <p class="card-text text-left">
            <span class="">Keywords:</span>
            
            <a
                    href="papers.html?filter=keywords&search=Knowledge-driven approaches to MIR -&gt; machine learning/artificial intelligence for music"
                    class="text-secondary text-decoration-none"
            >Knowledge-driven approaches to MIR -&gt; machine learning/artificial intelligence for music</a
            >,
            
            <a
                    href="papers.html?filter=keywords&search=Musical features and properties -&gt; rhythm, beat, tempo"
                    class="text-secondary text-decoration-none"
            >Musical features and properties -&gt; rhythm, beat, tempo</a
            >
            
        </p>
    </div>

</div>

<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <span class="font-weight-bold">Abstract:</span>
                <p>In this paper, we propose a novel Self-Supervised-Learning scheme to train rhythm analysis systems and instantiate it for few-shot beat tracking.   Taking inspiration from the Contrastive Predictive Coding paradigm, we propose to train a Log-Mel-Spectrogram-Transformer-encoder to contrast observations at times separated by hypothesized beat intervals from those that are not.   We do this without the knowledge of ground-truth tempo or beat positions, as we rely on the local maxima of a Predominant Local Pulse function, considered as a proxy for Tatum positions, to define candidate anchors, candidate positives (located at a distance of a power of two from the anchor) and negatives (remaining time positions).   We show that a model pre-trained using this approach on the unlabeled FMA, MTT and MTG-Jamendo datasets can successfully be fine-tuned in the few-shot regime, i.e. with just a few annotated examples to get a competitive beat-tracking performance.</p>
            </div>
        </div>
        <p></p>
    </div>
</div>


  
  <div class="text-center">
    <ul class="nav nav-tabs" id="posterTabs" role="tablist">
      <li class="nav-item" role="presentation">
        <a class="nav-link active" id="paper-tab" data-toggle="tab" href="#paper" role="tab" aria-controls="paper" aria-selected="true">Paper</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="poster-tab" data-toggle="tab" href="#poster" role="tab" aria-controls="poster" aria-selected="false">Poster</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="video-tab" data-toggle="tab" href="#video" role="tab" aria-controls="video" aria-selected="false">Video</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="Reviews-tab" data-toggle="tab" href="#Reviews" role="tab" aria-controls="Reviews" aria-selected="false">Reviews</a>
      </li>
    </ul>
  </div>
  

  <div class="tab-content" id="posterTabsContent">
    <div class="tab-pane fade show active" id="paper" role="tabpanel" aria-labelledby="paper-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/1ZCbNqs3QV7vhfH-HGAD6iaFzzZRvch_g/preview?usp=drive_link" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="poster" role="tabpanel" aria-labelledby="poster-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/1RWkcjSZM-yUW2tDEPU8_q42I7t6igv2Z/preview?usp=drive_link" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="video" role="tabpanel" aria-labelledby="video-tab">
      
      <div class="text-center">
        <div class="embed-responsive embed-responsive-16by9">
          <iframe class="embed-responsive-item"           
                  src="https://drive.google.com/file/d/1dBlcd_jNwcnBDoKOC1YZOkYYb90I1aSE/preview?usp=drive_link" 
                  frameborder="0" 
                  allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" 
                  allowfullscreen></iframe>
        </div>
      </div>
      
    </div>
    <div class="tab-pane fade" id="Reviews" role="tabpanel" aria-labelledby="Reviews-tab">
      <div class="pp-card m-3">
        <div class="card-body">
          <h5 class="card-title">
            Reviews
          </h5>
          <div class="card-text">
            
            <div> 
                <b> Meta Review </b> 
                <p> <p>All four reviewers agree on the acceptance of the paper. However, it is remarkable that all reviewers pick up the same weak points of the submission, and the authors have to address these in terms of clear comments and explanations (please see the detailed formulations in the reviews):
1. Restrictions due to the oversimplistic binary meter model.
2. With PLP as a basis, how does the system performance depend on genre, tempo stability. Also, more detail on the PLP parameters must be provided.
As meta-reviewer I would also add that you should explain how statistical significance was judged. </p></p>
              </div>
              <hr/>
        
            <div>
                <b> Review 1 </b>
                <p class="card-text"><p>This paper describes a contrastive pretraining method for beat tracking. The methods are highly novel. The use of a PLP for contrastive sample mining is very interesting and seemingly effective. The experiments are comprehensive on several datasets on both few-shot and full fine-tuning tasks.</p>
<p>Some questions:</p>
<p>Methodology:
The introduction of PLP helps solve the task of mining positive samples in beat tracking. The idea is highly novel and interesting. There seem to be some concerns about PLP: (1) How accurate it is for different genres? Will it be reasonably accurate if the music has rapid local tempo changes? (2) How likely are they to form binary-segmented tatums (i.e., 8-th notes) instead of ternary ones (i.e., 12-th notes)? 1-2 lines of description of preliminary experiments would help people get more sense of the feature.</p>
<p>Experiments:
Section 4.5: "Instead of ... of layer sequences." What is the weighted sum of layer sequences? Also, why choose a different fine-tuning scheme? Is linear probing not as good? Or, is there a specified reason?</p>
<p>Related works:
The idea of utilizing the binary rhythmic structure for self-supervised learning was previously used in [1].</p>
<p>The methodology of the paper could be beneficial to other rhythm-related downstream tasks, or even general pretraining models for MIR. Considering the novelty of the method and the concrete results, I recommend a strong acceptance with the possibility of an award nomination.</p>
<p>[1] Jiang, J., &amp; Xia, G. (2023, June). Self-Supervised Hierarchical Metrical Structure Modeling. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 1-5). IEEE.</p></p>
              </div>
            </div>
            <hr/>

            <div> 
                <b> Review 2 </b>
                <p>This work proposed a novel scheme to pretrain a network in a self-supervised manner using contrastive loss and finetune the network for beat tracking with few-shot learning; the results are comparable to the SOTA supervised models and nicely demonstrate the effectiveness of the methods. Considering that there are not many works for self-supervised beat tracking, and that the proposed methods are novel and perform promising, I originally would like to give a strong accept. However, due to the issues I mentioned in the reusable insight section and the following minor flaws, I have to weaken my acceptance to this work. </p>
<ul>
<li>Line 173: What does this binary structure mean here?</li>
<li>Line 182:This description is repeated several times in different ways; but the unit of the distance is not clear until this sentence. For example, Line 13,  line 165-169.</li>
<li>Line 409-416: The observation that the proposed model performs much better on Hainsworth is worthy of more discussions. Is it because that the model learns different knowledges or because of some special properties of Hainsworth? Without discussion, the reusable insight of this improvement is limited.</li>
<li>Line 462: rewrite the sentence: " where our the selection of anchor, positive and negative peaks derives from a Predominant Local Pulse function."</li>
<li>Line 236: alpha = 4 tu?</li>
</ul></p>
              </div>
              <hr/>


            <div> 
                <b> Review 3 </b>
                <p>The paper proposes a novel self-supervised learning (SSL) approach for rhythm analysis and tackles few-shot beat tracking. The learning strategy is based on contrastive learning and the pre-text task samples anchor, positive, and negative points from Predominant Local Pulse (PLP) maxima. These samples are used to train and encoder to contrast observations at beats (actually multiples of the tatum) from those that are not, using unlabelled data from FMA, MTT and MTG-Jamendo datasets. The pre-trained model is then fine-tuned with just a few annotated examples (i.e. few-shot) on the beat-tracking task. Results show the proposed approach outperforms an existing SSL method (Zero-Note Samba) and yiedls competitive results when compared to state-of-the-art supervised models.</p>
<p>The paper is well written and organized (despite some minor corrections listed below) and is a very good contribution to ISMIR. </p>
<p>The proposal has some clear limitations, though. First, the binary structure hypothesis does not hold for many music styles. Moreover, the sampling from the PLP makes the asumption that peaks are synchronized with 8-th notes and that the tracks are in 4/4. The authors acknowledge these are over-simplistic assumptions (line 174), but I encourage them to add some comments on how the proposal could be extended to non-binary music structures. One could think of other sampling strategies that may account for other meters, but this would probably require meter classification. </p>
<p>In adddition, relying on the PLP function has some drawbacks. Particularly, it can be noisy when there are tempo fluctuations or sudden tempo changes. The proposal deals with this kind of situation by filtering out tracks where the inter-peak distance of the PLP function is not almost constant (lines 375-380). Then, time-varing tempo is synthetically introduced through data augmentation during training.  This raises the question of to what extent the model can deal with tempo fluctuations within a song, so some insights on that would be welcome. </p>
<p>Experimental results confirm that the pre-trained model after fine-tuning can produce very competitive results, which seems to confirm that for the music datasets considered the assumptions are correct. Nevertheless, it would be interesting to test the model with music for which the over-simplistic assumptions do not hold and perform a detailed analysis of the results.  </p>
<p>There is no supplementary material, so I could not access the code, but the paper indicates that it will be available. It would be important that the pre-trained models and the code for the experiments are available to enhance scientific reproducibility.</p>
<p>Minor corrections</p>
<p>It seems that beat and tatum are never defined. A short clarification would be nice. </p>
<p>Line 35 - "at most a few thousands ..." refers to data, so something is missing here.</p>
<p>Note that there is an error in Figure 2. The time corresponding to yp should be in Ya, which means should be ya+ix\alpha, but in the diagram of Figure 2 it is located in between ya+2\alpha and ya+3\alpha. </p>
<p>Line 278 - typo: "thee" -&gt; "the"</p>
<p>Line 294 - remove "performances"</p>
<p>Line 461 - "our" should be removed</p></p>
              </div>
              <hr/>

            
            <div> 
            <b> Author description of changes: </b>
            <p>We would like to thank the reviewers and the meta-reviewer for their valuable feedback and suggestions.</p>
<p>We have corrected all the typos and restructured the paragraphs based on the reviewers' and meta-reviewer's remarks.</p>
<p>We added details about PLP computation.</p>
<p>Regarding the comments from Reviewers #1 and #2, we explained our decision to replace the linear probe and also included a reference to the section where we describe how we fed the probing network.</p>
<p>Reviewer #1:
    - Added a reference as requested.</p>
<p>Reviewer #2:
    - Added details about the safety window.
    - Added details about discarding audio segments.
    - Added details about the time-varying factor for data augmentation.
    - Clarified section 3.1.2 to make the tatum unit clearer.</p>
<p>Reviewer #3:
    - Corrected the figure.</p></p>
            </div>
                   
          </div>
                    
    
        </div>
      </div>
    
  </div>
  





  <script>
  document.addEventListener('DOMContentLoaded', function() {
    console.log(JSON.stringify("{&#39;id&#39;: &#39;283&#39;, &#39;session&#39;: &#39;1&#39;, &#39;position&#39;: &#39;20&#39;, &#39;forum&#39;: &#39;283&#39;, &#39;pic_id&#39;: &#39;https://drive.google.com/file/d/1BPmJ_BnweNHfHsrmFpmCzPF3Q7SdoMh9/view?usp=drive_link&#39;, &#39;content&#39;: {&#39;title&#39;: &#39;A Contrastive Self-Supervised Learning scheme for beat tracking amenable to few-shot learning&#39;, &#39;paper_presentation&#39;: &#39;San Francisco&#39;, &#39;long_presentation&#39;: &#39;FALSE&#39;, &#39;authors&#39;: [&#39;Gagneré, Antonin*&#39;, &#39; Essid, Slim&#39;, &#39; Peeters, Geoffroy&#39;], &#39;authors_and_affil&#39;: [&#39;Antonin Gagneré (LTCI - Télécom Paris, IP Paris)*&#39;, &#39; Slim Essid (  LTCI - Télécom Paris, IP Paris)&#39;, &#39; Geoffroy Peeters (LTCI - Télécom Paris, IP Paris)&#39;], &#39;keywords&#39;: [&#39;Knowledge-driven approaches to MIR -&gt; machine learning/artificial intelligence for music&#39;, &#39;Musical features and properties -&gt; rhythm, beat, tempo&#39;], &#39;abstract&#39;: &#39;In this paper, we propose a novel Self-Supervised-Learning scheme to train rhythm analysis systems and instantiate it for few-shot beat tracking.   Taking inspiration from the Contrastive Predictive Coding paradigm, we propose to train a Log-Mel-Spectrogram-Transformer-encoder to contrast observations at times separated by hypothesized beat intervals from those that are not.   We do this without the knowledge of ground-truth tempo or beat positions, as we rely on the local maxima of a Predominant Local Pulse function, considered as a proxy for Tatum positions, to define candidate anchors, candidate positives (located at a distance of a power of two from the anchor) and negatives (remaining time positions).   We show that a model pre-trained using this approach on the unlabeled FMA, MTT and MTG-Jamendo datasets can successfully be fine-tuned in the few-shot regime, i.e. with just a few annotated examples to get a competitive beat-tracking performance.&#39;, &#39;TLDR&#39;: &#39;In this paper, we propose a novel Self-Supervised-Learning scheme to train rhythm analysis systems and instantiate it for few-shot beat tracking.   Taking inspiration from the Contrastive Predictive Coding paradigm, we propose to train a Log-Mel-Spectrogram-Transformer-encoder to contrast observations at times separated by hypothesized beat intervals from those that are not.   We do this without the knowledge of ground-truth tempo or beat positions, as we rely on the local maxima of a Predominant Local Pulse function, considered as a proxy for Tatum positions, to define candidate anchors, candidate positives (located at a distance of a power of two from the anchor) and negatives (remaining time positions).   We show that a model pre-trained using this approach on the unlabeled FMA, MTT and MTG-Jamendo datasets can successfully be fine-tuned in the few-shot regime, i.e. with just a few annotated examples to get a competitive beat-tracking performance.&#39;, &#39;poster_pdf&#39;: &#39;https://drive.google.com/file/d/1RWkcjSZM-yUW2tDEPU8_q42I7t6igv2Z/view?usp=drive_link&#39;, &#39;session&#39;: [&#39;1&#39;], &#39;pdf_path&#39;: &#39;https://drive.google.com/file/d/1ZCbNqs3QV7vhfH-HGAD6iaFzzZRvch_g/view?usp=drive_link&#39;, &#39;video&#39;: &#39;https://drive.google.com/file/d/1dBlcd_jNwcnBDoKOC1YZOkYYb90I1aSE/view?usp=drive_link&#39;, &#39;channel_url&#39;: &#39;https://ismir2024.slack.com/archives/C07USGNN5C4&#39;, &#39;slack_channel&#39;: &#39;p1-19-a-contrastive-self&#39;, &#39;day&#39;: &#39;1&#39;, &#39;review_1&#39;: &#39;This paper describes a contrastive pretraining method for beat tracking. The methods are highly novel. The use of a PLP for contrastive sample mining is very interesting and seemingly effective. The experiments are comprehensive on several datasets on both few-shot and full fine-tuning tasks.\n\nSome questions:\n\nMethodology:\nThe introduction of PLP helps solve the task of mining positive samples in beat tracking. The idea is highly novel and interesting. There seem to be some concerns about PLP: (1) How accurate it is for different genres? Will it be reasonably accurate if the music has rapid local tempo changes? (2) How likely are they to form binary-segmented tatums (i.e., 8-th notes) instead of ternary ones (i.e., 12-th notes)? 1-2 lines of description of preliminary experiments would help people get more sense of the feature.\n\nExperiments:\nSection 4.5: &#34;Instead of ... of layer sequences.&#34; What is the weighted sum of layer sequences? Also, why choose a different fine-tuning scheme? Is linear probing not as good? Or, is there a specified reason?\n\nRelated works:\nThe idea of utilizing the binary rhythmic structure for self-supervised learning was previously used in [1].\n\nThe methodology of the paper could be beneficial to other rhythm-related downstream tasks, or even general pretraining models for MIR. Considering the novelty of the method and the concrete results, I recommend a strong acceptance with the possibility of an award nomination.\n\n[1] Jiang, J., &amp; Xia, G. (2023, June). Self-Supervised Hierarchical Metrical Structure Modeling. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 1-5). IEEE.\n&#39;, &#39;review_2&#39;: &#39;This work proposed a novel scheme to pretrain a network in a self-supervised manner using contrastive loss and finetune the network for beat tracking with few-shot learning; the results are comparable to the SOTA supervised models and nicely demonstrate the effectiveness of the methods. Considering that there are not many works for self-supervised beat tracking, and that the proposed methods are novel and perform promising, I originally would like to give a strong accept. However, due to the issues I mentioned in the reusable insight section and the following minor flaws, I have to weaken my acceptance to this work. \n\n- Line 173: What does this binary structure mean here?\n- Line 182:This description is repeated several times in different ways; but the unit of the distance is not clear until this sentence. For example, Line 13,  line 165-169.\n- Line 409-416: The observation that the proposed model performs much better on Hainsworth is worthy of more discussions. Is it because that the model learns different knowledges or because of some special properties of Hainsworth? Without discussion, the reusable insight of this improvement is limited.\n- Line 462: rewrite the sentence: &#34; where our the selection of anchor, positive and negative peaks derives from a Predominant Local Pulse function.&#34;\n- Line 236: alpha = 4 tu?\n\n\n&#39;, &#39;review_3&#39;: &#39;The paper proposes a novel self-supervised learning (SSL) approach for rhythm analysis and tackles few-shot beat tracking. The learning strategy is based on contrastive learning and the pre-text task samples anchor, positive, and negative points from Predominant Local Pulse (PLP) maxima. These samples are used to train and encoder to contrast observations at beats (actually multiples of the tatum) from those that are not, using unlabelled data from FMA, MTT and MTG-Jamendo datasets. The pre-trained model is then fine-tuned with just a few annotated examples (i.e. few-shot) on the beat-tracking task. Results show the proposed approach outperforms an existing SSL method (Zero-Note Samba) and yiedls competitive results when compared to state-of-the-art supervised models.\n\nThe paper is well written and organized (despite some minor corrections listed below) and is a very good contribution to ISMIR. \n\nThe proposal has some clear limitations, though. First, the binary structure hypothesis does not hold for many music styles. Moreover, the sampling from the PLP makes the asumption that peaks are synchronized with 8-th notes and that the tracks are in 4/4. The authors acknowledge these are over-simplistic assumptions (line 174), but I encourage them to add some comments on how the proposal could be extended to non-binary music structures. One could think of other sampling strategies that may account for other meters, but this would probably require meter classification. \n\nIn adddition, relying on the PLP function has some drawbacks. Particularly, it can be noisy when there are tempo fluctuations or sudden tempo changes. The proposal deals with this kind of situation by filtering out tracks where the inter-peak distance of the PLP function is not almost constant (lines 375-380). Then, time-varing tempo is synthetically introduced through data augmentation during training.  This raises the question of to what extent the model can deal with tempo fluctuations within a song, so some insights on that would be welcome. \n\nExperimental results confirm that the pre-trained model after fine-tuning can produce very competitive results, which seems to confirm that for the music datasets considered the assumptions are correct. Nevertheless, it would be interesting to test the model with music for which the over-simplistic assumptions do not hold and perform a detailed analysis of the results.  \n\nThere is no supplementary material, so I could not access the code, but the paper indicates that it will be available. It would be important that the pre-trained models and the code for the experiments are available to enhance scientific reproducibility.\n\nMinor corrections\n\nIt seems that beat and tatum are never defined. A short clarification would be nice. \n\nLine 35 - &#34;at most a few thousands ...&#34; refers to data, so something is missing here.\n\nNote that there is an error in Figure 2. The time corresponding to yp should be in Ya, which means should be ya+ix\\alpha, but in the diagram of Figure 2 it is located in between ya+2\\alpha and ya+3\\alpha. \n\nLine 278 - typo: &#34;thee&#34; -&gt; &#34;the&#34;\n\nLine 294 - remove &#34;performances&#34;\n\nLine 461 - &#34;our&#34; should be removed&#39;, &#39;meta_review&#39;: &#39;All four reviewers agree on the acceptance of the paper. However, it is remarkable that all reviewers pick up the same weak points of the submission, and the authors have to address these in terms of clear comments and explanations (please see the detailed formulations in the reviews):\n1. Restrictions due to the oversimplistic binary meter model.\n2. With PLP as a basis, how does the system performance depend on genre, tempo stability. Also, more detail on the PLP parameters must be provided.\nAs meta-reviewer I would also add that you should explain how statistical significance was judged. &#39;, &#39;author_changes&#39;: &#34;We would like to thank the reviewers and the meta-reviewer for their valuable feedback and suggestions.\n\nWe have corrected all the typos and restructured the paragraphs based on the reviewers&#39; and meta-reviewer&#39;s remarks.\n\nWe added details about PLP computation.\n\nRegarding the comments from Reviewers #1 and #2, we explained our decision to replace the linear probe and also included a reference to the section where we describe how we fed the probing network.\n\nReviewer #1:\n    - Added a reference as requested.\n\nReviewer #2:\n    - Added details about the safety window.\n    - Added details about discarding audio segments.\n    - Added details about the time-varying factor for data augmentation.\n    - Clarified section 3.1.2 to make the tatum unit clearer.\n\nReviewer #3:\n    - Corrected the figure.&#34;}, &#39;poster_pdf&#39;: &#39;GLTR_poster.pdf&#39;}"));
    // Ensure jQuery and Bootstrap are loaded
    if (typeof $ === 'undefined') {
      console.error('jQuery is not loaded');
      return;
    }
    
    // Initialize all tabs
    $('#posterTabs a').on('click', function (e) {
      e.preventDefault();
      $(this).tab('show');
    });
  
    // Show paper tab by default
    $('#posterTabs a[href="#paper"]').tab('show');
    MathJax.typesetPromise().then(() => {
    // modify the DOM here
        MathJax.typesetPromise();
    }).catch((err) => console.log(err.message));
  });
  </script>
  
  
    </div>
</div>



<!-- Google Analytics -->
<script
        async
        src="https://www.googletagmanager.com/gtag/js?id=UA-"
></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag("js", new Date());
  gtag("config", "UA-");
</script>

<!-- Footer -->
<footer class="footer bg-light p-4">
    <div class="container">
        <p class="float-right"><a href="#">Back to Top</a></p>
        <p class="text-center">© 2024 International Society for Music Information Retrieval</p>
    </div>
</footer>

<!-- Code for hash tags -->
<script type="text/javascript">
  $(document).ready(function () {
    if (window.location.hash !== "") {
      $(`a[href="${window.location.hash}"]`).tab("show");
    }

    $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
      const hash = $(e.target).attr("href");
      if (hash.substr(0, 1) === "#") {
        const position = $(window).scrollTop();
        window.location.replace(`#${hash.substr(1)}`);
        $(window).scrollTop(position);
      }
    });
   
  });
</script>
<!--    <script src="static/js/modules/lazyLoad.js"></script>-->

</body>
</html>