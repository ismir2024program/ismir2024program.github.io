

<!DOCTYPE html>
<html lang="en">
<head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8"/>
    <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script
            src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
            crossorigin="anonymous"
    ></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
            integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
            integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
            crossorigin="anonymous"></script>
            <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=Gantari:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Library libs_ext --> 
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin="anonymous" referrerpolicy="no-referrer" />


    <!--    Internal Libs -->
    <script src="static/js/data/api.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY="
          crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
            href="static/css/Lato.css"
            rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet"/>
    <link
            href="static/css/Cuprum.css"
            rel="stylesheet"
    />
    <link rel="stylesheet" href="static/css/main.css"/>
<!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css"/>
    <link rel="stylesheet" href="static/css/lazy_load.css"/>
    <link rel="stylesheet" href="static/css/typeahead.css"/>

    <title>ISMIR 2024</title>
    
<meta name="citation_title" content=""/>

<meta name="citation_publication_date" content="May 2024"/>
<meta name="citation_conference_title"
      content="Ismir 2024"/>
<meta name="citation_inbook_title" content="Proceedings of the 25th International Society for Music Information Retrieval"/>
<meta name="citation_abstract" content=""/>

<meta name="citation_pdf_url" content=""/>


</head>

<body>
<!-- NAV -->

<nav
        class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
        id="main-nav"
>
    <div class="container">
        <a class="navbar-brand" href="index.html">
            <img
                    class="logo" src="static/images/ismir24_logo.svg"
                    height="auto"
            width="95px"
            />
        </a>
        
        <button
                class="navbar-toggler"
                type="button"
                data-toggle="collapse"
                data-target="#navbarNav"
                aria-controls="navbarNav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div
                class="collapse navbar-collapse text-right flex-grow-1"
                id="navbarNav"
        >
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="index.html">Schedule</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="papers.html">Papers</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="tutorials.html">Tutorials</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="lbds.html">LBDs</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="industry.html">Industry</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="jobs.html">Jobs</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>



<!-- User Overrides -->
 

<div class="container">
    <!-- Tabs -->
    <div class="tabs">
         
    </div>
    <!-- Content -->
    <div class="content">
        
<div class="pp-card m-3" style="background-color: #fff">
    <div class="card-header" style="background-color: rgba(0,0,0,0);">
        <h2 class="card-title main-title text-left" style="color: #4383EC">
            A New Dataset, Notation Software, and Representation for Computational Schenkerian Analysis
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-left">
            
            <a href="papers.html?filter=authors&search=Stephen Hahn (Duke)*"
               class="text-muted"
            >Stephen Hahn (Duke)*</a
            >,
            
            <a href="papers.html?filter=authors&search= Weihan Xu (duke)"
               class="text-muted"
            > Weihan Xu (duke)</a
            >,
            
            <a href="papers.html?filter=authors&search= Zirui Yin (Duke University)"
               class="text-muted"
            > Zirui Yin (Duke University)</a
            >,
            
            <a href="papers.html?filter=authors&search= Rico Zhu (Duke University)"
               class="text-muted"
            > Rico Zhu (Duke University)</a
            >,
            
            <a href="papers.html?filter=authors&search= Simon Mak (Duke University)"
               class="text-muted"
            > Simon Mak (Duke University)</a
            >,
            
            <a href="papers.html?filter=authors&search= Yue Jiang (Duke University)"
               class="text-muted"
            > Yue Jiang (Duke University)</a
            >,
            
            <a href="papers.html?filter=authors&search= Cynthia Rudin (Duke)"
               class="text-muted"
            > Cynthia Rudin (Duke)</a
            >
            
        </h3>
        
        <div class="btn-group mb-3 mt-3">
          <a href="https://ismir2024.slack.com/archives/C07VCR7PY6L" class="btn btn-primary" style="background-color: #2294e0;"><svg style="display: inline-block; width: 23px;" version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="75 75 150 150" style="enable-background:new 0 0 270 270;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
</style>
<g>
	<g>
		<path class="st0" d="M99.4,151.2c0,7.1-5.8,12.9-12.9,12.9s-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h12.9V151.2z"/>
		<path class="st0" d="M105.9,151.2c0-7.1,5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v32.3c0,7.1-5.8,12.9-12.9,12.9
			s-12.9-5.8-12.9-12.9C105.9,183.5,105.9,151.2,105.9,151.2z"/>
	</g>
	<g>
		<path class="st0" d="M118.8,99.4c-7.1,0-12.9-5.8-12.9-12.9s5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v12.9H118.8z"/>
		<path class="st0" d="M118.8,105.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9H86.5c-7.1,0-12.9-5.8-12.9-12.9
			s5.8-12.9,12.9-12.9C86.5,105.9,118.8,105.9,118.8,105.9z"/>
	</g>
	<g>
		<path class="st0" d="M170.6,118.8c0-7.1,5.8-12.9,12.9-12.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9h-12.9V118.8z"/>
		<path class="st0" d="M164.1,118.8c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9V86.5c0-7.1,5.8-12.9,12.9-12.9
			c7.1,0,12.9,5.8,12.9,12.9V118.8z"/>
	</g>
	<g>
		<path class="st0" d="M151.2,170.6c7.1,0,12.9,5.8,12.9,12.9c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9v-12.9H151.2z"/>
		<path class="st0" d="M151.2,164.1c-7.1,0-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h32.3c7.1,0,12.9,5.8,12.9,12.9
			c0,7.1-5.8,12.9-12.9,12.9H151.2z"/>
	</g>
</g>
</svg> p6-06-a-new-dataset</a>
        </div>
        
        <p class="card-text text-left">
            <span class="">Keywords:</span>
            
            <a
                    href="papers.html?filter=keywords&search=Human-centered MIR -&gt; music interfaces and services; MIR fundamentals and methodology -&gt; symbolic music processing; Musical features and properties -&gt; structure, segmentation, and form"
                    class="text-secondary text-decoration-none"
            >Human-centered MIR -&gt; music interfaces and services; MIR fundamentals and methodology -&gt; symbolic music processing; Musical features and properties -&gt; structure, segmentation, and form</a
            >,
            
            <a
                    href="papers.html?filter=keywords&search=Evaluation, datasets, and reproducibility -&gt; novel datasets and use cases"
                    class="text-secondary text-decoration-none"
            >Evaluation, datasets, and reproducibility -&gt; novel datasets and use cases</a
            >
            
        </p>
    </div>

</div>

<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <span class="font-weight-bold">Abstract:</span>
                <p>Schenkerian Analysis (SchA) is a uniquely expressive method of music analysis, combining elements of melody, harmony, counterpoint, and form to describe the hierarchical structure supporting a work of music. However, despite its powerful analytical utility and potential to improve music understanding and generation, SchA has rarely been utilized by the computer music community. This is in large part due to the paucity of available high-quality data in a computer-readable format. With a larger corpus of Schenkerian data, it may be possible to infuse machine learning models with a deeper understanding of musical structure, leading to more "human" results.  To encourage further research in Schenkerian analysis and its potential benefits for music informatics and generation, this paper presents three main contributions: 1) a new and growing dataset of SchAs, the largest in human- and computer-readable formats to date (&gt;140 excerpts), 2) a novel software for visualization and collection of SchA data, and 3) a novel, flexible representation of SchA as a heterogeneous-edge graph data structure.</p>
            </div>
        </div>
        <p></p>
    </div>
</div>


  
  <div class="text-center">
    <ul class="nav nav-tabs" id="posterTabs" role="tablist">
      <li class="nav-item" role="presentation">
        <a class="nav-link active" id="paper-tab" data-toggle="tab" href="#paper" role="tab" aria-controls="paper" aria-selected="true">Paper</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="poster-tab" data-toggle="tab" href="#poster" role="tab" aria-controls="poster" aria-selected="false">Poster</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="video-tab" data-toggle="tab" href="#video" role="tab" aria-controls="video" aria-selected="false">Video</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="Reviews-tab" data-toggle="tab" href="#Reviews" role="tab" aria-controls="Reviews" aria-selected="false">Reviews</a>
      </li>
    </ul>
  </div>
  

  <div class="tab-content" id="posterTabsContent">
    <div class="tab-pane fade show active" id="paper" role="tabpanel" aria-labelledby="paper-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/19RtCI-wJZy7RKj7oEz7gD-94TMkdRPIb/preview?usp=drive_link" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="poster" role="tabpanel" aria-labelledby="poster-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/1ME_Waz-jgKrb5fOavvJYK97jwteeVLYf/preview?usp=drive_link" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="video" role="tabpanel" aria-labelledby="video-tab">
      
      <div class="text-center">
        <div class="embed-responsive embed-responsive-16by9">
          <iframe class="embed-responsive-item"           
                  src="https://drive.google.com/file/d/1mx1xF6y1fZBStu2DGS_5gp6RSQ9qIIUX/preview?usp=drive_link" 
                  frameborder="0" 
                  allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" 
                  allowfullscreen></iframe>
        </div>
      </div>
      
    </div>
    <div class="tab-pane fade" id="Reviews" role="tabpanel" aria-labelledby="Reviews-tab">
      <div class="pp-card m-3">
        <div class="card-body">
          <h5 class="card-title">
            Reviews
          </h5>
          <div class="card-text">
            
            <div> 
                <b> Meta Review </b> 
                <p> <p>All the reviewers appreciated that the paper is well-written and clear, with an appropriate bibliography, and is scientifically sound, making it a valuable contribution to the community.</p>
<p>Some remarks were done about the availability of the data (all reviewers) and some suggestions of improvement were made, to explain more in details the dataset, its metadata and its links to other datasets (R2, R3, MR), to provide more details on the notation software (R2) and to improve and clarify the figures (all reviewers).</p>
<p>Please take into account those comments for the final version of your paper.</p></p>
              </div>
              <hr/>
        
            <div>
                <b> Review 1 </b>
                <p class="card-text"><p>I greatly congratulate the authors on their work! I am pleased to see initiatives that move from black-box models to generative tasks and focus on more interpretable models, especially applied to complex and often subjective tasks like Schenkerian analysis. The brief explanation of Schenkerian analysis in Section 1.1 helps the reader who is not an expert in the subject to understand minimally what the process entails. Furthermore, throughout the work, the authors take care to discuss musically their points, always using the same example.</p>
<p>I have a few minor suggestions for the authors:</p>
<ul>
<li>
<p>In lines 219 to 221, the authors mention that the dataset consists of pieces from the common practice period, Gentle Giant, and others. I must admit, I am very curious to know what falls in between! For example, are there rock pieces with simpler melodies/harmonies, like Elvis Presley, Beatles? As a big fan of Gentle Giant, I'm aware that they make extensive use of ideas from common practice in their pieces (e.g., Knots, In Reflection), but with a significant harmonic and melodic modernization. To what extent can the usual Schenkerian analysis capture these nuances? I ask this because I am aware of a work of Schenkerian analysis applied to Brazilian Popular Music (https://www.scielo.br/j/pm/a/Q93rFfZWy49cm9xjb3mwCQt/?format=pdf in Portuguese -- I hope the authors can read it, as I do not know their nationality), and some adaptations are necessary to capture specific nuances of the aesthetic.</p>
</li>
<li>
<p>Will the software be made public? Open-source? Freeware? I understand that the software may still be unsuitable for widespread use in its current state, but it is important to mention the future of the software for readers who might want to use it.</p>
</li>
<li>
<p>I know that positioning figures in LaTeX is difficult, but Figs. 2 and 3 appear after Fig. 4. It would be good to fix that.</p>
</li>
<li>
<p>Using a single color in the bar graph of Fig. 3 would make it easier to read.</p>
</li>
<li>
<p>In Fig. 4, having the x-axis ticks every 1 would be helpful.</p>
</li>
<li>
<p>The proposal could also be used to assist in teaching Schenkerian analysis! Perhaps this is something important to mention.</p>
</li>
</ul>
<p>I conclude my comments once again by congratulating the authors for tackling a complex problem!</p></p>
              </div>
            </div>
            <hr/>

            <div> 
                <b> Review 2 </b>
                <p>The paper is well-written and clearly organized, with a thorough bibliography. The context is well set on Schenkerian analysis. The encoding formats and graphical representations (fig.2b) are convincing. It has three main contributions. Whereas the graph structure is well detailed in Section 3 (and supported by Figure 5, which is enlightening), I would expect more details for both the dataset and especially the notation software.</p>
<p>The dataset:
- Its process of creation can be slightly more detailed. Regardless of the name of the analysts (who could even remain anonymous after the publication), it can be useful to know more about their respective experience (experts in music composition, musicology, Schenkerian analysis? ; level/years of practice?). Any annotation guidelines specific to the format or tool used, any potential source of disagreement (potentially reduced by a reviewing process between analysts for example)?
- Indicate where the dataset would be available, even in a submission, with an fake/anonymous URL. As the dataset is meant to grow, it also becomes important to number the versions/releases of your dataset to make experiments reproducible (for possible "We trained our model on 'SchA' Dataset V1.1.7 (180 samples)") and keep track of the evolution.
  - In that sense, I recommend saving JSON format (which is already a sensible choice for machine- and human-readability) in unfolded versions to make them more human-readable, and easier to track changes in version control systems. (In supplementary material, provided samples are one-liners)
- Stick with the current number of analyses: 145 -- even if future versions will include more of them.
- The analyses of some statistics of the dataset is appreciated. Some comments in l.243-268 are important to understand the figures/table, and should be added in their captions, to make the figures more readable, more autonomous.
- Provide more information about the metadata. If not in the paper, at least in a summary file in the dataset location.</p>
<p>The notation software:
- In current state, the dataset and graph representation are the main contributions of the paper; and they are valuable. The software appears primarily as a tool that the authors (or analysts) used to produce and read the data. But it is not well documented, although it appears in the title.
- Among other questions:
  - What technology or language is used?
  - Is it a script to run, an executable, a web application? This can be critical for accessibility, if the goal is to facilitate SchA annotation at scale.
  - How the user interact with the system? If it displays the graphical representation of an JSON annotation, it is already interesting, but it needs to be explicitly mentioned. Can users interact the graphical representation, with JSON or both? What is an example of "simple commands" (l.275)?
- l.279: In this context, the formulation "We are currently working on..." leaves a feeling of unfinished work. Nevertheless, it is completely okay to indicate what the features of current version are, and then evoke separately other features to be included in a future release. (minor issue)</p>
<p>I believe the contributions of this paper are valuable, but it has to be made clear whether:
- 1. the software can be used as it is by the community, and it is a major : in this case, it needs more details to be understood <em>how</em>.
- or 2. it is a tool to facilitate building the dataset: in this case, it is a program which is part of the creation process of the dataset; it is not the main topic of this paper, and can be removed from the title. This framework is still precious and the code usable by the community.</p>
<p>Minor comments on the form:
- If possible, improve the position of figures so that more references are on the same pages as their figure, especially Figures 2, 3 and 4. Try splitting 3a and 3b in two separate figures (even if they stay at the same position). As mentioned before, captions can be more explicit.
- Some use of quotes sometimes put unnecessary distance. l.126 "fractal" is justified if it comes from the reference (same for "goodness metric" l.153), but "big data" l.23, "atonal" l.74, "human" l.13 (?), "ground truth" l.198 are better established concepts that can be in plain text, or in italic if it really needs to stand out.
- 1.1 and 1.2 can form an autonomous Section 2 "History of computational SchA / State of the art / Related work", separate from the introduction, which sounds concluding after the outlines in l.101-105.</p></p>
              </div>
              <hr/>


            <div> 
                <b> Review 3 </b>
                <p>This paper introduces an extension to a previously not so explored dataset, incorporating Schenkerian analyses of classical music. The newly added data focuses mostly on monophonic short fugal themes from the Baroque era. In my view, any open-source dataset constitutes a valuable asset for the community. Moreover, the availability of expert musicological annotations for Schenkerian analysis is both rare and precious.</p>
<p>Here are some comments and suggestions for the authors:</p>
<ol>
<li>
<p>Availability of Data: It is mentioned in the paper that the dataset contains 145 new excerpts, but there is no clear indication in the paper regarding whether this data will be made publicly available. If it is intended to be public, I recommend including an anonymized link in the paper or explicitly stating its public availability in the final version.</p>
</li>
<li>
<p>Clarity on Dataset Composition: From the examples provided and the supplementary material, it is implied that most of the data consists of short monophonic melodies. It would be beneficial for clarity if the authors explicitly state this information in the text if this is the case, otherwise I would highly suggest to include a more complete polyphonic example since space allows it. The excerpts depicted in Figure 4 may not fully convey this aspect, hence clarifying it within the text would be a plus for clarity.</p>
</li>
<li>
<p>Clarification on Clustering Example: The clustering example presented in Figure 5 prompts the question of whether only pairs of note contractions are allowed for each level transition. In Schenkerian analysis, multiple notes can be reduced from the Foreground to the Middleground in a single step. While this doesn't pose a significant issue, it may be prudent to mention this fact within the paper to enhance clarity.</p>
</li>
<li>
<p>Integration with Pre-existing Datasets: A key aspect of any new dataset paper is linking the new data with existing datasets. This is particularly crucial for smaller-scale musicological datasets. Given that the dataset in this paper includes fugal themes from the Well-Tempered Clavier (WTC), it could complement the ALGOMUS Bach fugues dataset effectively. I strongly recommend that the authors associate any related fugal themes from their dataset with existing datasets in the future (and add it as future work), as multi-level analyses are especially valuable in sparse musicological datasets.</p>
</li>
</ol></p>
              </div>
              <hr/>

            
            <div> 
            <b> Author description of changes: </b>
            <p>We added information about the analysts, availability of the dataset and notation software, and technology used for the notation software. Additionally, several small clarity edits were made, such as added plot ticks, rearranging of figure location, etc.</p></p>
            </div>
                   
          </div>
                    
    
        </div>
      </div>
    
  </div>
  





  <script>
  document.addEventListener('DOMContentLoaded', function() {
    console.log(JSON.stringify("{&#39;id&#39;: &#39;367&#39;, &#39;session&#39;: &#39;6&#39;, &#39;position&#39;: &#39;07&#39;, &#39;forum&#39;: &#39;367&#39;, &#39;pic_id&#39;: &#39;https://drive.google.com/file/d/18VRICoSc5LG6v_g1NaXDOciRyR9IBUa0/view?usp=drive_link&#39;, &#39;content&#39;: {&#39;title&#39;: &#39;A New Dataset, Notation Software, and Representation for Computational Schenkerian Analysis&#39;, &#39;paper_presentation&#39;: &#39;San Francisco&#39;, &#39;long_presentation&#39;: &#39;FALSE&#39;, &#39;authors&#39;: [&#39;Hahn, Stephen*&#39;, &#39; Xu, Weihan&#39;, &#39; Yin, Zirui&#39;, &#39; Zhu, Rico&#39;, &#39; Mak, Simon&#39;, &#39; Jiang, Yue&#39;, &#39; Rudin, Cynthia&#39;], &#39;authors_and_affil&#39;: [&#39;Stephen Hahn (Duke)*&#39;, &#39; Weihan Xu (duke)&#39;, &#39; Zirui Yin (Duke University)&#39;, &#39; Rico Zhu (Duke University)&#39;, &#39; Simon Mak (Duke University)&#39;, &#39; Yue Jiang (Duke University)&#39;, &#39; Cynthia Rudin (Duke)&#39;], &#39;keywords&#39;: [&#39;Human-centered MIR -&gt; music interfaces and services; MIR fundamentals and methodology -&gt; symbolic music processing; Musical features and properties -&gt; structure, segmentation, and form&#39;, &#39;Evaluation, datasets, and reproducibility -&gt; novel datasets and use cases&#39;], &#39;abstract&#39;: &#39;Schenkerian Analysis (SchA) is a uniquely expressive method of music analysis, combining elements of melody, harmony, counterpoint, and form to describe the hierarchical structure supporting a work of music. However, despite its powerful analytical utility and potential to improve music understanding and generation, SchA has rarely been utilized by the computer music community. This is in large part due to the paucity of available high-quality data in a computer-readable format. With a larger corpus of Schenkerian data, it may be possible to infuse machine learning models with a deeper understanding of musical structure, leading to more &#34;human&#34; results.  To encourage further research in Schenkerian analysis and its potential benefits for music informatics and generation, this paper presents three main contributions: 1) a new and growing dataset of SchAs, the largest in human- and computer-readable formats to date (&gt;140 excerpts), 2) a novel software for visualization and collection of SchA data, and 3) a novel, flexible representation of SchA as a heterogeneous-edge graph data structure.&#39;, &#39;TLDR&#39;: &#39;Schenkerian Analysis (SchA) is a uniquely expressive method of music analysis, combining elements of melody, harmony, counterpoint, and form to describe the hierarchical structure supporting a work of music. However, despite its powerful analytical utility and potential to improve music understanding and generation, SchA has rarely been utilized by the computer music community. This is in large part due to the paucity of available high-quality data in a computer-readable format. With a larger corpus of Schenkerian data, it may be possible to infuse machine learning models with a deeper understanding of musical structure, leading to more &#34;human&#34; results.  To encourage further research in Schenkerian analysis and its potential benefits for music informatics and generation, this paper presents three main contributions: 1) a new and growing dataset of SchAs, the largest in human- and computer-readable formats to date (&gt;140 excerpts), 2) a novel software for visualization and collection of SchA data, and 3) a novel, flexible representation of SchA as a heterogeneous-edge graph data structure.&#39;, &#39;poster_pdf&#39;: &#39;https://drive.google.com/file/d/1ME_Waz-jgKrb5fOavvJYK97jwteeVLYf/view?usp=drive_link&#39;, &#39;session&#39;: [&#39;6&#39;], &#39;pdf_path&#39;: &#39;https://drive.google.com/file/d/19RtCI-wJZy7RKj7oEz7gD-94TMkdRPIb/view?usp=drive_link&#39;, &#39;video&#39;: &#39;https://drive.google.com/file/d/1mx1xF6y1fZBStu2DGS_5gp6RSQ9qIIUX/view?usp=drive_link&#39;, &#39;channel_url&#39;: &#39;https://ismir2024.slack.com/archives/C07VCR7PY6L&#39;, &#39;slack_channel&#39;: &#39;p6-06-a-new-dataset&#39;, &#39;day&#39;: &#39;3&#39;, &#39;review_1&#39;: &#34;I greatly congratulate the authors on their work! I am pleased to see initiatives that move from black-box models to generative tasks and focus on more interpretable models, especially applied to complex and often subjective tasks like Schenkerian analysis. The brief explanation of Schenkerian analysis in Section 1.1 helps the reader who is not an expert in the subject to understand minimally what the process entails. Furthermore, throughout the work, the authors take care to discuss musically their points, always using the same example.\n\nI have a few minor suggestions for the authors:\n\n* In lines 219 to 221, the authors mention that the dataset consists of pieces from the common practice period, Gentle Giant, and others. I must admit, I am very curious to know what falls in between! For example, are there rock pieces with simpler melodies/harmonies, like Elvis Presley, Beatles? As a big fan of Gentle Giant, I&#39;m aware that they make extensive use of ideas from common practice in their pieces (e.g., Knots, In Reflection), but with a significant harmonic and melodic modernization. To what extent can the usual Schenkerian analysis capture these nuances? I ask this because I am aware of a work of Schenkerian analysis applied to Brazilian Popular Music (https://www.scielo.br/j/pm/a/Q93rFfZWy49cm9xjb3mwCQt/?format=pdf in Portuguese -- I hope the authors can read it, as I do not know their nationality), and some adaptations are necessary to capture specific nuances of the aesthetic.\n\n* Will the software be made public? Open-source? Freeware? I understand that the software may still be unsuitable for widespread use in its current state, but it is important to mention the future of the software for readers who might want to use it.\n\n* I know that positioning figures in LaTeX is difficult, but Figs. 2 and 3 appear after Fig. 4. It would be good to fix that.\n\n* Using a single color in the bar graph of Fig. 3 would make it easier to read.\n\n* In Fig. 4, having the x-axis ticks every 1 would be helpful.\n\n* The proposal could also be used to assist in teaching Schenkerian analysis! Perhaps this is something important to mention.\n\nI conclude my comments once again by congratulating the authors for tackling a complex problem!&#34;, &#39;review_2&#39;: &#39;The paper is well-written and clearly organized, with a thorough bibliography. The context is well set on Schenkerian analysis. The encoding formats and graphical representations (fig.2b) are convincing. It has three main contributions. Whereas the graph structure is well detailed in Section 3 (and supported by Figure 5, which is enlightening), I would expect more details for both the dataset and especially the notation software.\n\nThe dataset:\n- Its process of creation can be slightly more detailed. Regardless of the name of the analysts (who could even remain anonymous after the publication), it can be useful to know more about their respective experience (experts in music composition, musicology, Schenkerian analysis? ; level/years of practice?). Any annotation guidelines specific to the format or tool used, any potential source of disagreement (potentially reduced by a reviewing process between analysts for example)?\n- Indicate where the dataset would be available, even in a submission, with an fake/anonymous URL. As the dataset is meant to grow, it also becomes important to number the versions/releases of your dataset to make experiments reproducible (for possible &#34;We trained our model on \&#39;SchA\&#39; Dataset V1.1.7 (180 samples)&#34;) and keep track of the evolution.\n  - In that sense, I recommend saving JSON format (which is already a sensible choice for machine- and human-readability) in unfolded versions to make them more human-readable, and easier to track changes in version control systems. (In supplementary material, provided samples are one-liners)\n- Stick with the current number of analyses: 145 -- even if future versions will include more of them.\n- The analyses of some statistics of the dataset is appreciated. Some comments in l.243-268 are important to understand the figures/table, and should be added in their captions, to make the figures more readable, more autonomous.\n- Provide more information about the metadata. If not in the paper, at least in a summary file in the dataset location.\n\nThe notation software:\n- In current state, the dataset and graph representation are the main contributions of the paper; and they are valuable. The software appears primarily as a tool that the authors (or analysts) used to produce and read the data. But it is not well documented, although it appears in the title.\n- Among other questions:\n  - What technology or language is used?\n  - Is it a script to run, an executable, a web application? This can be critical for accessibility, if the goal is to facilitate SchA annotation at scale.\n  - How the user interact with the system? If it displays the graphical representation of an JSON annotation, it is already interesting, but it needs to be explicitly mentioned. Can users interact the graphical representation, with JSON or both? What is an example of &#34;simple commands&#34; (l.275)?\n- l.279: In this context, the formulation &#34;We are currently working on...&#34; leaves a feeling of unfinished work. Nevertheless, it is completely okay to indicate what the features of current version are, and then evoke separately other features to be included in a future release. (minor issue)\n\nI believe the contributions of this paper are valuable, but it has to be made clear whether:\n- 1. the software can be used as it is by the community, and it is a major : in this case, it needs more details to be understood *how*.\n- or 2. it is a tool to facilitate building the dataset: in this case, it is a program which is part of the creation process of the dataset; it is not the main topic of this paper, and can be removed from the title. This framework is still precious and the code usable by the community.\n\nMinor comments on the form:\n- If possible, improve the position of figures so that more references are on the same pages as their figure, especially Figures 2, 3 and 4. Try splitting 3a and 3b in two separate figures (even if they stay at the same position). As mentioned before, captions can be more explicit.\n- Some use of quotes sometimes put unnecessary distance. l.126 &#34;fractal&#34; is justified if it comes from the reference (same for &#34;goodness metric&#34; l.153), but &#34;big data&#34; l.23, &#34;atonal&#34; l.74, &#34;human&#34; l.13 (?), &#34;ground truth&#34; l.198 are better established concepts that can be in plain text, or in italic if it really needs to stand out.\n- 1.1 and 1.2 can form an autonomous Section 2 &#34;History of computational SchA / State of the art / Related work&#34;, separate from the introduction, which sounds concluding after the outlines in l.101-105.&#39;, &#39;review_3&#39;: &#34;This paper introduces an extension to a previously not so explored dataset, incorporating Schenkerian analyses of classical music. The newly added data focuses mostly on monophonic short fugal themes from the Baroque era. In my view, any open-source dataset constitutes a valuable asset for the community. Moreover, the availability of expert musicological annotations for Schenkerian analysis is both rare and precious.\n\nHere are some comments and suggestions for the authors:\n\n1. Availability of Data: It is mentioned in the paper that the dataset contains 145 new excerpts, but there is no clear indication in the paper regarding whether this data will be made publicly available. If it is intended to be public, I recommend including an anonymized link in the paper or explicitly stating its public availability in the final version.\n\n2. Clarity on Dataset Composition: From the examples provided and the supplementary material, it is implied that most of the data consists of short monophonic melodies. It would be beneficial for clarity if the authors explicitly state this information in the text if this is the case, otherwise I would highly suggest to include a more complete polyphonic example since space allows it. The excerpts depicted in Figure 4 may not fully convey this aspect, hence clarifying it within the text would be a plus for clarity.\n\n3. Clarification on Clustering Example: The clustering example presented in Figure 5 prompts the question of whether only pairs of note contractions are allowed for each level transition. In Schenkerian analysis, multiple notes can be reduced from the Foreground to the Middleground in a single step. While this doesn&#39;t pose a significant issue, it may be prudent to mention this fact within the paper to enhance clarity.\n\n4. Integration with Pre-existing Datasets: A key aspect of any new dataset paper is linking the new data with existing datasets. This is particularly crucial for smaller-scale musicological datasets. Given that the dataset in this paper includes fugal themes from the Well-Tempered Clavier (WTC), it could complement the ALGOMUS Bach fugues dataset effectively. I strongly recommend that the authors associate any related fugal themes from their dataset with existing datasets in the future (and add it as future work), as multi-level analyses are especially valuable in sparse musicological datasets.&#34;, &#39;meta_review&#39;: &#39;All the reviewers appreciated that the paper is well-written and clear, with an appropriate bibliography, and is scientifically sound, making it a valuable contribution to the community.\n\nSome remarks were done about the availability of the data (all reviewers) and some suggestions of improvement were made, to explain more in details the dataset, its metadata and its links to other datasets (R2, R3, MR), to provide more details on the notation software (R2) and to improve and clarify the figures (all reviewers).\n\nPlease take into account those comments for the final version of your paper.&#39;, &#39;author_changes&#39;: &#39;We added information about the analysts, availability of the dataset and notation software, and technology used for the notation software. Additionally, several small clarity edits were made, such as added plot ticks, rearranging of figure location, etc.&#39;}, &#39;poster_pdf&#39;: &#39;GLTR_poster.pdf&#39;}"));
    // Ensure jQuery and Bootstrap are loaded
    if (typeof $ === 'undefined') {
      console.error('jQuery is not loaded');
      return;
    }
    
    // Initialize all tabs
    $('#posterTabs a').on('click', function (e) {
      e.preventDefault();
      $(this).tab('show');
    });
  
    // Show paper tab by default
    $('#posterTabs a[href="#paper"]').tab('show');
    MathJax.typesetPromise().then(() => {
    // modify the DOM here
        MathJax.typesetPromise();
    }).catch((err) => console.log(err.message));
  });
  </script>
  
  
    </div>
</div>



<!-- Google Analytics -->
<script
        async
        src="https://www.googletagmanager.com/gtag/js?id=UA-"
></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag("js", new Date());
  gtag("config", "UA-");
</script>

<!-- Footer -->
<footer class="footer bg-light p-4">
    <div class="container">
        <p class="float-right"><a href="#">Back to Top</a></p>
        <p class="text-center">© 2024 International Society for Music Information Retrieval</p>
    </div>
</footer>

<!-- Code for hash tags -->
<script type="text/javascript">
  $(document).ready(function () {
    if (window.location.hash !== "") {
      $(`a[href="${window.location.hash}"]`).tab("show");
    }

    $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
      const hash = $(e.target).attr("href");
      if (hash.substr(0, 1) === "#") {
        const position = $(window).scrollTop();
        window.location.replace(`#${hash.substr(1)}`);
        $(window).scrollTop(position);
      }
    });
   
  });
</script>
<!--    <script src="static/js/modules/lazyLoad.js"></script>-->

</body>
</html>