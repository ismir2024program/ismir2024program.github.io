

<!DOCTYPE html>
<html lang="en">
<head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8"/>
    <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script
            src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
            crossorigin="anonymous"
    ></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
            integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
            integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
            crossorigin="anonymous"></script>
            <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=Gantari:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Library libs_ext --> 
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin="anonymous" referrerpolicy="no-referrer" />


    <!--    Internal Libs -->
    <script src="static/js/data/api.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY="
          crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
            href="static/css/Lato.css"
            rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet"/>
    <link
            href="static/css/Cuprum.css"
            rel="stylesheet"
    />
    <link rel="stylesheet" href="static/css/main.css"/>
<!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css"/>
    <link rel="stylesheet" href="static/css/lazy_load.css"/>
    <link rel="stylesheet" href="static/css/typeahead.css"/>

    <title>ISMIR 2024</title>
    
<meta name="citation_title" content=""/>

<meta name="citation_publication_date" content="May 2024"/>
<meta name="citation_conference_title"
      content="Ismir 2024"/>
<meta name="citation_inbook_title" content="Proceedings of the 25th International Society for Music Information Retrieval"/>
<meta name="citation_abstract" content=""/>

<meta name="citation_pdf_url" content=""/>


</head>

<body>
<!-- NAV -->

<nav
        class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
        id="main-nav"
>
    <div class="container">
        <a class="navbar-brand" href="index.html">
            <img
                    class="logo" src="static/images/ismir24_logo.svg"
                    height="auto"
            width="95px"
            />
        </a>
        
        <button
                class="navbar-toggler"
                type="button"
                data-toggle="collapse"
                data-target="#navbarNav"
                aria-controls="navbarNav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div
                class="collapse navbar-collapse text-right flex-grow-1"
                id="navbarNav"
        >
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="index.html">Schedule</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="papers.html">Papers</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="tutorials.html">Tutorials</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="lbds.html">LBDs</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="industry.html">Industry</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="jobs.html">Jobs</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>



<!-- User Overrides -->
 

<div class="container">
    <!-- Tabs -->
    <div class="tabs">
         
    </div>
    <!-- Content -->
    <div class="content">
        
<div class="pp-card m-3" style="background-color: #fff">
    <div class="card-header" style="background-color: rgba(0,0,0,0);">
        <h2 class="card-title main-title text-left" style="color: #4383EC">
            Saraga Audiovisual: a large multimodal open data collection for the analysis of Carnatic Music
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-left">
            
            <a href="papers.html?filter=authors&search=Sivasankar, Adithi Shankar*"
               class="text-muted"
            >Sivasankar, Adithi Shankar*</a
            >,
            
            <a href="papers.html?filter=authors&search= Plaja-Roglans, Genís"
               class="text-muted"
            > Plaja-Roglans, Genís</a
            >,
            
            <a href="papers.html?filter=authors&search= Nuttall, Thomas"
               class="text-muted"
            > Nuttall, Thomas</a
            >,
            
            <a href="papers.html?filter=authors&search= Rocamora, Martín"
               class="text-muted"
            > Rocamora, Martín</a
            >,
            
            <a href="papers.html?filter=authors&search= Serra, Xavier"
               class="text-muted"
            > Serra, Xavier</a
            >
            
        </h3>
        
        <div class="btn-group ml-3 mb-3">
          <a href="https://ismir2024.slack.com/archives/C07V2MXCN65" class="btn btn-primary" style="background-color: #2294e0;"><svg style="display: inline-block; width: 23px;" version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="75 75 150 150" style="enable-background:new 0 0 270 270;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
</style>
<g>
	<g>
		<path class="st0" d="M99.4,151.2c0,7.1-5.8,12.9-12.9,12.9s-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h12.9V151.2z"/>
		<path class="st0" d="M105.9,151.2c0-7.1,5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v32.3c0,7.1-5.8,12.9-12.9,12.9
			s-12.9-5.8-12.9-12.9C105.9,183.5,105.9,151.2,105.9,151.2z"/>
	</g>
	<g>
		<path class="st0" d="M118.8,99.4c-7.1,0-12.9-5.8-12.9-12.9s5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v12.9H118.8z"/>
		<path class="st0" d="M118.8,105.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9H86.5c-7.1,0-12.9-5.8-12.9-12.9
			s5.8-12.9,12.9-12.9C86.5,105.9,118.8,105.9,118.8,105.9z"/>
	</g>
	<g>
		<path class="st0" d="M170.6,118.8c0-7.1,5.8-12.9,12.9-12.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9h-12.9V118.8z"/>
		<path class="st0" d="M164.1,118.8c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9V86.5c0-7.1,5.8-12.9,12.9-12.9
			c7.1,0,12.9,5.8,12.9,12.9V118.8z"/>
	</g>
	<g>
		<path class="st0" d="M151.2,170.6c7.1,0,12.9,5.8,12.9,12.9c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9v-12.9H151.2z"/>
		<path class="st0" d="M151.2,164.1c-7.1,0-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h32.3c7.1,0,12.9,5.8,12.9,12.9
			c0,7.1-5.8,12.9-12.9,12.9H151.2z"/>
	</g>
</g>
</svg> p1-02-saraga-audiovisual-a</a>
        </div>
        
        <p class="card-text text-left">
            <span class="">Keywords:</span>
            
            <a
                    href="papers.html?filter=keywords&search=Applications -&gt; music videos, multimodal music systems; Evaluation, datasets, and reproducibility -&gt; novel datasets and use cases; Knowledge-driven approaches to MIR -&gt; computational ethnomusicology; MIR tasks -&gt; pattern matching and detection; MIR tasks -&gt; sound source separation"
                    class="text-secondary text-decoration-none"
            >Applications -&gt; music videos, multimodal music systems; Evaluation, datasets, and reproducibility -&gt; novel datasets and use cases; Knowledge-driven approaches to MIR -&gt; computational ethnomusicology; MIR tasks -&gt; pattern matching and detection; MIR tasks -&gt; sound source separation</a
            >,
            
            <a
                    href="papers.html?filter=keywords&search=Computational musicology"
                    class="text-secondary text-decoration-none"
            >Computational musicology</a
            >
            
        </p>
    </div>

</div>

<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <span class="font-weight-bold">Abstract:</span>
                <p>Carnatic music is a style of South Indian art music whose analysis using computational methods is an active area of research in Music Information Research (MIR). A core, open dataset for such analysis is the Saraga dataset, which includes multi-stem audio, expert annotations, and accompanying metadata. However, it has been noted that there are several limitations to the Saraga collections, and that additional relevant aspects of the tradition still need to be covered to facilitate musicologically important research lines. In this work, we present Saraga Audiovisual, a dataset that includes new and more diverse renditions of Carnatic vocal performances, totalling 42 concerts and more than 60 hours of music. A major contribution of this dataset is the inclusion of video recordings for all concerts, allowing for a wide range of multimodal analyses. We also provide high-quality human pose estimation data of the musicians extracted from the video footage, and perform benchmarking experiments for the different modalities to validate the utility of the novel collection. Saraga Audiovisual, along with access tools and results of our experiments, is made available for research purposes.</p>
            </div>
        </div>
        <p></p>
    </div>
</div>


  
  <div class="text-center">
    <ul class="nav nav-tabs" id="posterTabs" role="tablist">
      <li class="nav-item" role="presentation">
        <a class="nav-link active" id="paper-tab" data-toggle="tab" href="#paper" role="tab" aria-controls="paper" aria-selected="true">Paper</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="poster-tab" data-toggle="tab" href="#poster" role="tab" aria-controls="poster" aria-selected="false">Poster</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="video-tab" data-toggle="tab" href="#video" role="tab" aria-controls="video" aria-selected="false">Video</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="Reviews-tab" data-toggle="tab" href="#Reviews" role="tab" aria-controls="Reviews" aria-selected="false">Reviews</a>
      </li>
    </ul>
  </div>
  

  <div class="tab-content" id="posterTabsContent">
    <div class="tab-pane fade show active" id="paper" role="tabpanel" aria-labelledby="paper-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/1EQXLNuxVj3e60R2Eovj8U4saxajWlXac/preview" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="poster" role="tabpanel" aria-labelledby="poster-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/1dSina5Drt9bNlrD4KEr4FXYmpbSTOkyh/preview" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="video" role="tabpanel" aria-labelledby="video-tab">
      
      <div class="text-center">
        <div class="embed-responsive embed-responsive-16by9">
          <iframe class="embed-responsive-item"           
                  src="https://drive.google.com/file/d/1Hn3rqQxlbgnb69IGcw8hZj53CRzNeqYm/preview?usp=share_link" 
                  frameborder="0" 
                  allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" 
                  allowfullscreen></iframe>
        </div>
      </div>
      
    </div>
    <div class="tab-pane fade" id="Reviews" role="tabpanel" aria-labelledby="Reviews-tab">
      <div class="pp-card m-3">
        <div class="card-body">
          <h5 class="card-title">
            Reviews
          </h5>
          <div class="card-text">
            
            <div> 
                <b> Meta Review </b> 
                <p> <p>The intention to augment the available Carnatic music dataset is laudable. The dataset will be undoubtedly useful for future MIR work on Carnatic music. However, the annotation and validation analyses seemed to have been completed in a hurry.  Please go through the comments by the 3 reviewers who have pointed out several aspects that need attention in order to make this a truly valuable resource.</p></p>
              </div>
              <hr/>
        
            <div>
                <b> Review 1 </b>
                <p class="card-text"><p>The paper proposes Saraga Carnatic 2.0: a large multimodal open data collection for analyzing Carnatic music. The paper reads well; however, the organization of the Experiments section could be reworked as some of the content is parallel and does not adhere to a causal flow. The authors refer to the existing dataset by 3 different names: Saraga, original Saraga, and Saraga1.0, which should be consistent. Innuendos such as “nature of Carnatic music” (line 459) may be avoided as this is a loaded statement, and a Spleeter model to learn such nuance while preserving the knowledge warrants more detailed discourse on the process.</p>
<p>I have reservations about the argument that melodic motif annotations are unreasonable for manifold reasons. On the one hand, the authors acknowledge improving motif recognition as a useful task (line 188) and identify regions of repeated melodic motifs (line 312). On the other hand, advocating the lack of importance of the annotation task is counterintuitive. Most newly added ragas have only 1 occurrence, as evident from Figure 1. In the absence of several and balanced instances of a raga class, it is imperative that this dataset is not suitable for a raga classification task. This defeats the claim of new raga additions scaling the same (line 187).</p>
<p>The video analysis of the gesture modeling is well-written. However, the demo video shows that the performer keeps the meter by clapping gesture, with one active hand (right) and the other complementing. In this scenario, one would expect the kinetics to be related to stress points in the rhythmic progression. Thus, it would be interesting to have inferences on the individual differences between Ashwin and Prithvi on the vast difference of the same correlation values of 0.36 and 0.11, respectively. My final concern is about the effectiveness of calling the proposed dataset as an extension of Saraga. Like the authors think about having an independent identity of the instrumental dataset, calling this Saraga2.0 also warrants a thorough demonstration of the improvements expanding on Section 3.4, especially on the melody re-computation aspect.</p></p>
              </div>
            </div>
            <hr/>

            <div> 
                <b> Review 2 </b>
                <p>The paper introduces an extended version of the Carnatic part of the Saraga dataset, presenting experimental results on music-motion relation analysis and music source separation.</p>
<p>Strengths
The proposed dataset offers a large amount of data with various ragas and talas. The addition of video recordings and automatic pose estimation results can be beneficial for research on the relationship between music and motion, which has recently gained popularity in Indian art music research. The paper also includes feedback from the research community on the previous version of the dataset, demonstrating exemplary progress in open science. The reproduction of Pearson et al.'s analysis using the new dataset shows the usefulness of automatically annotated pose information.</p>
<p>Weakness
- The fine-tuning result for the music source separation model, presented in section 4.2, does not strongly support the validation of this dataset's usefulness. This is not only because the fine-tuning degraded the model's performance on vocal artifacts, but also because similar experiments and results were already provided with Saraga 1.0 [17]. MSS can be fine-tuned for Carnatic music with Saraga 1.0, so it is not the exclusive usefulness of Saraga 2.0. The authors should explicitly show the advantage of using additional data from Saraga 2.0, such as by comparing a model trained only with Saraga 1.0 and a model trained with both Saraga 1.0 and 2.0.
- Including video is an interesting aspect of this dataset. However, the camera angle is not appropriate for capturing the posture of the violinist or mridangist. While the main interest in motion analysis might be the singer, the microphone and the stand obscure the singer's hand, as mentioned by the authors. In this sense, the dataset is not ideal for video analysis compared to other previous video recordings of vocal performances in Indian art music [16]. The authors should report the stability of the MMPose results, such as whether there was a sudden jump in hand location in the estimated gestures.
- It is not clear, but it seems that the paintings in the background are also detected as human postures. Additionally, it would be better for users if the pose estimation was provided separately for the singer and other players.</p>
<p>Minor comments
- In Table 1, it is not clear how the sum of Saraga 1.0 and 2.0 would look in terms of the total number of ragas or talas.
- I think the explanation on excluding instrumental Carnatic music can be shorten into one single sentence. It is worth mentioning that the current dataset does not cover instrumental Carnatic music, but I don't think the author has to justify why they are focusing on vocal-centered music with extensive paragraphs. The comparison with slakh sounds bit unnatural to me, as slakh used synthesizer. 
- It is not clear how many subjects participated in the listening test in Table 3. Also, the standard deviation or confidence interval has to be provided. 
- Saraga 1.0 also includes Hindustani music, but it is not clear how this will be handled in dataset access 
- There are duplicated sentences in line 224
- Line 353: "for which the p-value is less than our significance level of 0.00001 are excluded" – Should this be "greater than the significance level"?
- Some words in the References, such as Carnatic and Turkish, need to be capitalized in the camera-ready version.</p></p>
              </div>
              <hr/>


            <div> 
                <b> Review 3 </b>
                <p>The manuscript presents extension to Saraga Carnatic dataset. Along with increasing coverage of various ragas, concerts, the new version introduces video recordings of the concerts for multimodal MIR research. The paper is well organised and well written, certain tasks are also benchmarked with the extended dataset.</p></p>
              </div>
              <hr/>

            
            <div> 
            <b> Author description of changes: </b>
            <ul>
<li>We have updated the naming convention of the dataset for clarity, and we have been consistent throughout the paper.</li>
<li>We have improved the discussion on the video gathering to address the raised comments and questions by the Reviewers.</li>
<li>We have included separation results of fine-tuned Spleeter using Saraga and Saraga Audiovisual (the new dataset) and improved the discussion on the relevance of these benchmarking experiments. We do not report fine-tuning experiments on the combination of Saraga and Saraga Audiovisual as our intention is to study the impact of each data collection process separately.</li>
<li>We have included missing details in the perceptual test results.</li>
</ul>
<p>Let us further comment on the questions about the video footage:
- The video gesture experiments are performed only on voice only excerpts called the alapana. These sections are not metered and also do not contain any rhythmic accompaniment.  The demo video is used only to show excerpts from the dataset and not correlated to the videos used for the gesture experiments. Figure 2 in the paper demonstrates the vocalist singing a composition in a rhythmic meter, but is illustrative of the video data in general and is not indicative of the alapana section on which the gesture experiments are perfomed. Figure 3 illustrates the vocalist singing an alapana.
- The video recordings are recorded from concert venues in the usual stage setting of the artists. In Carnatic music, the vocalist receives most prominence. Keeping in mind that the microphone placed directly in front of the vocalist causes visual occlusions of the mouth and the gestures made, several pose estimation models were tested before selecting the MMPose 2D-Top down model. This model manages to capture regions prone to occlusions like the singer’s mouth and the hands with a good level of accuracy. </p></p>
            </div>
                   
          </div>
                    
    
        </div>
      </div>
    
  </div>
  





  <script>
  document.addEventListener('DOMContentLoaded', function() {
    console.log(JSON.stringify("{&#39;id&#39;: &#39;352&#39;, &#39;session&#39;: &#39;1&#39;, &#39;position&#39;: &#39;03&#39;, &#39;forum&#39;: &#39;352&#39;, &#39;pic_id&#39;: &#39;https://drive.google.com/file/d/1WLVY2eot7RHjB-PrJXrM5Q-JEQ2kt0uB/view?usp=share_link&#39;, &#39;content&#39;: {&#39;title&#39;: &#39;Saraga Audiovisual: a large multimodal open data collection for the analysis of Carnatic Music&#39;, &#39;paper_presentation&#39;: &#39;San Francisco&#39;, &#39;long_presentation&#39;: &#39;FALSE&#39;, &#39;authors&#39;: [&#39;Sivasankar, Adithi Shankar*&#39;, &#39; Plaja-Roglans, Genís&#39;, &#39; Nuttall, Thomas&#39;, &#39; Rocamora, Martín&#39;, &#39; Serra, Xavier&#39;], &#39;authors_and_affil&#39;: [&#39;Adithi Shankar (Music Technology Group- Universitat Pompeu Fabra)*&#39;, &#39; Genís Plaja-Roglans (Music Technology Group)&#39;, &#39; Thomas Nuttall (Universitat Pompeu Fabra, Barcelona)&#39;, &#39; Martín Rocamora (Universitat Pompeu Fabra)&#39;, &#39; Xavier Serra (Universitat Pompeu Fabra )&#39;], &#39;keywords&#39;: [&#39;Applications -&gt; music videos, multimodal music systems; Evaluation, datasets, and reproducibility -&gt; novel datasets and use cases; Knowledge-driven approaches to MIR -&gt; computational ethnomusicology; MIR tasks -&gt; pattern matching and detection; MIR tasks -&gt; sound source separation&#39;, &#39;Computational musicology&#39;], &#39;abstract&#39;: &#39;Carnatic music is a style of South Indian art music whose analysis using computational methods is an active area of research in Music Information Research (MIR). A core, open dataset for such analysis is the Saraga dataset, which includes multi-stem audio, expert annotations, and accompanying metadata. However, it has been noted that there are several limitations to the Saraga collections, and that additional relevant aspects of the tradition still need to be covered to facilitate musicologically important research lines. In this work, we present Saraga Audiovisual, a dataset that includes new and more diverse renditions of Carnatic vocal performances, totalling 42 concerts and more than 60 hours of music. A major contribution of this dataset is the inclusion of video recordings for all concerts, allowing for a wide range of multimodal analyses. We also provide high-quality human pose estimation data of the musicians extracted from the video footage, and perform benchmarking experiments for the different modalities to validate the utility of the novel collection. Saraga Audiovisual, along with access tools and results of our experiments, is made available for research purposes.&#39;, &#39;TLDR&#39;: &#39;Carnatic music is a style of South Indian art music whose analysis using computational methods is an active area of research in Music Information Research (MIR). A core, open dataset for such analysis is the Saraga dataset, which includes multi-stem audio, expert annotations, and accompanying metadata. However, it has been noted that there are several limitations to the Saraga collections, and that additional relevant aspects of the tradition still need to be covered to facilitate musicologically important research lines. In this work, we present Saraga Audiovisual, a dataset that includes new and more diverse renditions of Carnatic vocal performances, totalling 42 concerts and more than 60 hours of music. A major contribution of this dataset is the inclusion of video recordings for all concerts, allowing for a wide range of multimodal analyses. We also provide high-quality human pose estimation data of the musicians extracted from the video footage, and perform benchmarking experiments for the different modalities to validate the utility of the novel collection. Saraga Audiovisual, along with access tools and results of our experiments, is made available for research purposes.&#39;, &#39;poster_pdf&#39;: &#39;https://drive.google.com/file/d/1dSina5Drt9bNlrD4KEr4FXYmpbSTOkyh/view?usp=sharing&#39;, &#39;session&#39;: [&#39;1&#39;], &#39;pdf_path&#39;: &#39;https://drive.google.com/file/d/1EQXLNuxVj3e60R2Eovj8U4saxajWlXac/view?usp=sharing&#39;, &#39;video&#39;: &#39;https://drive.google.com/file/d/1Hn3rqQxlbgnb69IGcw8hZj53CRzNeqYm/view?usp=share_link&#39;, &#39;channel_url&#39;: &#39;https://ismir2024.slack.com/archives/C07V2MXCN65&#39;, &#39;slack_channel&#39;: &#39;p1-02-saraga-audiovisual-a&#39;, &#39;day&#39;: &#39;1&#39;, &#39;review_1&#39;: &#39;The paper proposes Saraga Carnatic 2.0: a large multimodal open data collection for analyzing Carnatic music. The paper reads well; however, the organization of the Experiments section could be reworked as some of the content is parallel and does not adhere to a causal flow. The authors refer to the existing dataset by 3 different names: Saraga, original Saraga, and Saraga1.0, which should be consistent. Innuendos such as “nature of Carnatic music” (line 459) may be avoided as this is a loaded statement, and a Spleeter model to learn such nuance while preserving the knowledge warrants more detailed discourse on the process.\n\nI have reservations about the argument that melodic motif annotations are unreasonable for manifold reasons. On the one hand, the authors acknowledge improving motif recognition as a useful task (line 188) and identify regions of repeated melodic motifs (line 312). On the other hand, advocating the lack of importance of the annotation task is counterintuitive. Most newly added ragas have only 1 occurrence, as evident from Figure 1. In the absence of several and balanced instances of a raga class, it is imperative that this dataset is not suitable for a raga classification task. This defeats the claim of new raga additions scaling the same (line 187).\n\nThe video analysis of the gesture modeling is well-written. However, the demo video shows that the performer keeps the meter by clapping gesture, with one active hand (right) and the other complementing. In this scenario, one would expect the kinetics to be related to stress points in the rhythmic progression. Thus, it would be interesting to have inferences on the individual differences between Ashwin and Prithvi on the vast difference of the same correlation values of 0.36 and 0.11, respectively. My final concern is about the effectiveness of calling the proposed dataset as an extension of Saraga. Like the authors think about having an independent identity of the instrumental dataset, calling this Saraga2.0 also warrants a thorough demonstration of the improvements expanding on Section 3.4, especially on the melody re-computation aspect.&#39;, &#39;review_2&#39;: &#39;The paper introduces an extended version of the Carnatic part of the Saraga dataset, presenting experimental results on music-motion relation analysis and music source separation.\n\nStrengths\nThe proposed dataset offers a large amount of data with various ragas and talas. The addition of video recordings and automatic pose estimation results can be beneficial for research on the relationship between music and motion, which has recently gained popularity in Indian art music research. The paper also includes feedback from the research community on the previous version of the dataset, demonstrating exemplary progress in open science. The reproduction of Pearson et al.\&#39;s analysis using the new dataset shows the usefulness of automatically annotated pose information.\n\nWeakness\n- The fine-tuning result for the music source separation model, presented in section 4.2, does not strongly support the validation of this dataset\&#39;s usefulness. This is not only because the fine-tuning degraded the model\&#39;s performance on vocal artifacts, but also because similar experiments and results were already provided with Saraga 1.0 [17]. MSS can be fine-tuned for Carnatic music with Saraga 1.0, so it is not the exclusive usefulness of Saraga 2.0. The authors should explicitly show the advantage of using additional data from Saraga 2.0, such as by comparing a model trained only with Saraga 1.0 and a model trained with both Saraga 1.0 and 2.0.\n- Including video is an interesting aspect of this dataset. However, the camera angle is not appropriate for capturing the posture of the violinist or mridangist. While the main interest in motion analysis might be the singer, the microphone and the stand obscure the singer\&#39;s hand, as mentioned by the authors. In this sense, the dataset is not ideal for video analysis compared to other previous video recordings of vocal performances in Indian art music [16]. The authors should report the stability of the MMPose results, such as whether there was a sudden jump in hand location in the estimated gestures.\n- It is not clear, but it seems that the paintings in the background are also detected as human postures. Additionally, it would be better for users if the pose estimation was provided separately for the singer and other players.\n\nMinor comments\n- In Table 1, it is not clear how the sum of Saraga 1.0 and 2.0 would look in terms of the total number of ragas or talas.\n- I think the explanation on excluding instrumental Carnatic music can be shorten into one single sentence. It is worth mentioning that the current dataset does not cover instrumental Carnatic music, but I don\&#39;t think the author has to justify why they are focusing on vocal-centered music with extensive paragraphs. The comparison with slakh sounds bit unnatural to me, as slakh used synthesizer. \n- It is not clear how many subjects participated in the listening test in Table 3. Also, the standard deviation or confidence interval has to be provided. \n- Saraga 1.0 also includes Hindustani music, but it is not clear how this will be handled in dataset access \n- There are duplicated sentences in line 224\n- Line 353: &#34;for which the p-value is less than our significance level of 0.00001 are excluded&#34; – Should this be &#34;greater than the significance level&#34;?\n- Some words in the References, such as Carnatic and Turkish, need to be capitalized in the camera-ready version.&#39;, &#39;review_3&#39;: &#39;The manuscript presents extension to Saraga Carnatic dataset. Along with increasing coverage of various ragas, concerts, the new version introduces video recordings of the concerts for multimodal MIR research. The paper is well organised and well written, certain tasks are also benchmarked with the extended dataset.&#39;, &#39;meta_review&#39;: &#39;The intention to augment the available Carnatic music dataset is laudable. The dataset will be undoubtedly useful for future MIR work on Carnatic music. However, the annotation and validation analyses seemed to have been completed in a hurry.  Please go through the comments by the 3 reviewers who have pointed out several aspects that need attention in order to make this a truly valuable resource.&#39;, &#39;author_changes&#39;: &#39;- We have updated the naming convention of the dataset for clarity, and we have been consistent throughout the paper.\n- We have improved the discussion on the video gathering to address the raised comments and questions by the Reviewers.\n- We have included separation results of fine-tuned Spleeter using Saraga and Saraga Audiovisual (the new dataset) and improved the discussion on the relevance of these benchmarking experiments. We do not report fine-tuning experiments on the combination of Saraga and Saraga Audiovisual as our intention is to study the impact of each data collection process separately.\n- We have included missing details in the perceptual test results.\n\nLet us further comment on the questions about the video footage:\n- The video gesture experiments are performed only on voice only excerpts called the alapana. These sections are not metered and also do not contain any rhythmic accompaniment.\xa0 The demo video is used only to show excerpts from the dataset and not correlated to the videos used for the gesture experiments. Figure 2 in the paper demonstrates the vocalist singing a composition in a rhythmic meter, but is illustrative of the video data in general and is not indicative of the alapana section on which the gesture experiments are perfomed. Figure 3 illustrates the vocalist singing an alapana.\n- The video recordings are recorded from concert venues in the usual stage setting of the artists. In Carnatic music, the vocalist receives most prominence. Keeping in mind that the microphone placed directly in front of the vocalist causes visual occlusions of the mouth and the gestures made, several pose estimation models were tested before selecting the MMPose 2D-Top down model. This model manages to capture regions prone to occlusions like the singer’s mouth and the hands with a good level of accuracy. &#39;}, &#39;poster_pdf&#39;: &#39;GLTR_poster.pdf&#39;}"));
    // Ensure jQuery and Bootstrap are loaded
    if (typeof $ === 'undefined') {
      console.error('jQuery is not loaded');
      return;
    }
    
    // Initialize all tabs
    $('#posterTabs a').on('click', function (e) {
      e.preventDefault();
      $(this).tab('show');
    });
  
    // Show paper tab by default
    $('#posterTabs a[href="#paper"]').tab('show');
    MathJax.typesetPromise().then(() => {
    // modify the DOM here
        MathJax.typesetPromise();
    }).catch((err) => console.log(err.message));
  });
  </script>
  
  
    </div>
</div>



<!-- Google Analytics -->
<script
        async
        src="https://www.googletagmanager.com/gtag/js?id=UA-"
></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag("js", new Date());
  gtag("config", "UA-");
</script>

<!-- Footer -->
<footer class="footer bg-light p-4">
    <div class="container">
        <p class="float-right"><a href="#">Back to Top</a></p>
        <p class="text-center">© 2024 International Society for Music Information Retrieval</p>
    </div>
</footer>

<!-- Code for hash tags -->
<script type="text/javascript">
  $(document).ready(function () {
    if (window.location.hash !== "") {
      $(`a[href="${window.location.hash}"]`).tab("show");
    }

    $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
      const hash = $(e.target).attr("href");
      if (hash.substr(0, 1) === "#") {
        const position = $(window).scrollTop();
        window.location.replace(`#${hash.substr(1)}`);
        $(window).scrollTop(position);
      }
    });
   
  });
</script>
<!--    <script src="static/js/modules/lazyLoad.js"></script>-->

</body>
</html>