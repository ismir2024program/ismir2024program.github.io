

<!DOCTYPE html>
<html lang="en">
<head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8"/>
    <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script
            src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
            crossorigin="anonymous"
    ></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
            integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
            integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
            crossorigin="anonymous"></script>
            <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=Gantari:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Library libs_ext --> 
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin="anonymous" referrerpolicy="no-referrer" />


    <!--    Internal Libs -->
    <script src="static/js/data/api.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY="
          crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
            href="static/css/Lato.css"
            rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet"/>
    <link
            href="static/css/Cuprum.css"
            rel="stylesheet"
    />
    <link rel="stylesheet" href="static/css/main.css"/>
<!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css"/>
    <link rel="stylesheet" href="static/css/lazy_load.css"/>
    <link rel="stylesheet" href="static/css/typeahead.css"/>

    <title>MiniConf 2024</title>
    
<meta name="citation_title" content=""/>

<meta name="citation_publication_date" content="May 2024"/>
<meta name="citation_conference_title"
      content="Ismir 2024"/>
<meta name="citation_inbook_title" content="Proceedings of the 25th International Society for Music Information Retrieval"/>
<meta name="citation_abstract" content=""/>

<meta name="citation_pdf_url" content=""/>


</head>

<body>
<!-- NAV -->

<nav
        class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
        id="main-nav"
>
    <div class="container">
        <a class="navbar-brand" href="index.html">
            <img
                    class="logo" src="static/images/ismir24_logo.svg"
                    height="auto"
            width="95px"
            />
        </a>
        
        <button
                class="navbar-toggler"
                type="button"
                data-toggle="collapse"
                data-target="#navbarNav"
                aria-controls="navbarNav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div
                class="collapse navbar-collapse text-right flex-grow-1"
                id="navbarNav"
        >
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="index.html">Schedule</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="papers.html">Papers</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="tutorials.html">Tutorials</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="lbds.html">LBDs</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>



<!-- User Overrides -->
 

<div class="container">
    <!-- Tabs -->
    <div class="tabs">
         
    </div>
    <!-- Content -->
    <div class="content">
        
<div class="pp-card m-3" style="background-color: #fff">
    <div class="card-header" style="background-color: rgba(0,0,0,0);">
        <h2 class="card-title main-title text-left" style="color: #4383EC">
            A Kalman Filter model for synchronization in musical ensembles
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-left">
            
            <a href="papers.html?filter=authors&search=Carvalho, Hugo T*"
               class="text-muted"
            >Carvalho, Hugo T*</a
            >,
            
            <a href="papers.html?filter=authors&search= Li, Min Susan"
               class="text-muted"
            > Li, Min Susan</a
            >,
            
            <a href="papers.html?filter=authors&search= Di Luca, Massimiliano"
               class="text-muted"
            > Di Luca, Massimiliano</a
            >,
            
            <a href="papers.html?filter=authors&search= Wing, Alan M."
               class="text-muted"
            > Wing, Alan M.</a
            >
            
        </h3>
        
        <div class="btn-group ml-3 mb-3">
          <a href="https://ismir2024.slack.com/archives/C07U9F9FQLF" class="btn btn-primary" style="background-color: #2294e0;"><svg style="display: inline-block; width: 23px;" version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="75 75 150 150" style="enable-background:new 0 0 270 270;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
</style>
<g>
	<g>
		<path class="st0" d="M99.4,151.2c0,7.1-5.8,12.9-12.9,12.9s-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h12.9V151.2z"/>
		<path class="st0" d="M105.9,151.2c0-7.1,5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v32.3c0,7.1-5.8,12.9-12.9,12.9
			s-12.9-5.8-12.9-12.9C105.9,183.5,105.9,151.2,105.9,151.2z"/>
	</g>
	<g>
		<path class="st0" d="M118.8,99.4c-7.1,0-12.9-5.8-12.9-12.9s5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v12.9H118.8z"/>
		<path class="st0" d="M118.8,105.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9H86.5c-7.1,0-12.9-5.8-12.9-12.9
			s5.8-12.9,12.9-12.9C86.5,105.9,118.8,105.9,118.8,105.9z"/>
	</g>
	<g>
		<path class="st0" d="M170.6,118.8c0-7.1,5.8-12.9,12.9-12.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9h-12.9V118.8z"/>
		<path class="st0" d="M164.1,118.8c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9V86.5c0-7.1,5.8-12.9,12.9-12.9
			c7.1,0,12.9,5.8,12.9,12.9V118.8z"/>
	</g>
	<g>
		<path class="st0" d="M151.2,170.6c7.1,0,12.9,5.8,12.9,12.9c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9v-12.9H151.2z"/>
		<path class="st0" d="M151.2,164.1c-7.1,0-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h32.3c7.1,0,12.9,5.8,12.9,12.9
			c0,7.1-5.8,12.9-12.9,12.9H151.2z"/>
	</g>
</g>
</svg> p4-16-a-kalman-filter</a>
        </div>
        
        <p class="card-text text-left">
            <span class="">Keywords:</span>
            
            <a
                    href="papers.html?filter=keywords&search=Musical features and properties"
                    class="text-secondary text-decoration-none"
            >Musical features and properties</a
            >,
            
            <a
                    href="papers.html?filter=keywords&search=MIR tasks -&gt; alignment, synchronization, and score following; Musical features and properties -&gt; expression and performative aspects of music; Musical features and properties -&gt; rhythm, beat, tempo"
                    class="text-secondary text-decoration-none"
            >MIR tasks -&gt; alignment, synchronization, and score following; Musical features and properties -&gt; expression and performative aspects of music; Musical features and properties -&gt; rhythm, beat, tempo</a
            >
            
        </p>
    </div>

</div>

<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <span class="font-weight-bold">Abstract:</span>
                <p>The synchronization of motor responses to rhythmic auditory cues is a fundamental biological phenomenon observed across various species. While the importance of temporal alignment varies across different contexts, achieving precise temporal synchronization is a prominent goal in musical performances. Musicians often incorporate expressive timing variations, which require precise control over timing and synchronization, particularly in ensemble performance. This is crucial because both deliberate expressive nuances and accidental timing deviations can affect the overall timing of a performance. This discussion prompts the question of how musicians adjust their temporal dynamics to achieve synchronization within an ensemble. This paper introduces a novel feedback correction model based on the Kalman Filter, aimed at improving the understanding of interpersonal timing in ensemble music performances. The proposed model performs similarly to other linear correction models in the literature, with the advantage of low computational cost and good performance even in scenarios where the underlying tempo varies.</p>
            </div>
        </div>
        <p></p>
    </div>
</div>


  
  <div class="text-center">
    <ul class="nav nav-tabs" id="posterTabs" role="tablist">
      <li class="nav-item" role="presentation">
        <a class="nav-link active" id="paper-tab" data-toggle="tab" href="#paper" role="tab" aria-controls="paper" aria-selected="true">Paper</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="poster-tab" data-toggle="tab" href="#poster" role="tab" aria-controls="poster" aria-selected="false">Poster</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="video-tab" data-toggle="tab" href="#video" role="tab" aria-controls="video" aria-selected="false">Video</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="Reviews-tab" data-toggle="tab" href="#Reviews" role="tab" aria-controls="Reviews" aria-selected="false">Reviews</a>
      </li>
    </ul>
  </div>
  

  <div class="tab-content" id="posterTabsContent">
    <div class="tab-pane fade show active" id="paper" role="tabpanel" aria-labelledby="paper-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/1xbuQojY3c7U5aBISEmYQbcgdSrHE7IMA/preview" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="poster" role="tabpanel" aria-labelledby="poster-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/1PaMyuIzsGJRpviccxxaaSnHvOku7Wjg3/preview" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="video" role="tabpanel" aria-labelledby="video-tab">
      
      <div class="text-center">
        <div class="embed-responsive embed-responsive-16by9">
          <iframe class="embed-responsive-item"           
                  src="https://drive.google.com/file/d/1YKoc_qGkB-_kV3iYWly-RBG5QGwl3cnE/preview" 
                  frameborder="0" 
                  allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" 
                  allowfullscreen></iframe>
        </div>
      </div>
      
    </div>
    <div class="tab-pane fade" id="Reviews" role="tabpanel" aria-labelledby="Reviews-tab">
      <div class="pp-card m-3">
        <div class="card-body">
          <h5 class="card-title">
            Reviews
          </h5>
          <div class="card-text">
            
            <div> 
                <b> Meta Review </b> 
                <p> <p>The reviewers all agree that the music syntonization problem is well formulated reconciling music cognition and the KF approach is a promising approach. Reviewer #3 emphasized that this framework has a lot of potential in other MIR tasks as well. At the same time, all reviewers pointed out that the evaluation part is weak. Specifically, the experiment was conducted on a small dataset in limited music scenarios. The results are presented qualitatively without model comparison. Nevertheless, all reviewers are generally in favor of this paper, mainly because of its potential impact on the ISMIR community.</p></p>
              </div>
              <hr/>
        
            <div>
                <b> Review 1 </b>
                <p class="card-text"><p>The paper is well written and clear. I'm not an expert on how to analyze temporal alignment and synchronization between musician in an ensemble, but it was not difficult to follow the technical details, also thankfully for the clarity of the exposition. The Kalman Filter is ubiquitous and it has been proven effective also in studying how precise temporal synchronization between performers in a musical ensemble is achieved. The phase correction strength seems to be a good indicator for knowing which instruments are the leaders, and which are the followers. The results show on the Op. 74 no. 1 by Joseph Haydn are quite impressive to me. As I mentioned I'm not an expert on this very specific topic, so, unfortunately I do not know the literature, and nor the state of the art of the syncrony analysis. Give that, I red the paper with pleasure and it flows like a familiar topic to me. It would be nice to have a thorough evaluation also on other music ensemble examples. But I understand that the dataset can be a problem since this is a very specific ground truth that is not simple to obtain. Moreover, I can imagine some implication also in other MIR topics, like score followers and also generative models can use the phase correction gain to model the "humanity" of the timing of a computer generated music.</p></p>
              </div>
            </div>
            <hr/>

            <div> 
                <b> Review 2 </b>
                <p>The paper presents a linear model for ensemble synchronization using Kalman Filter. It essentially uses time-dependent version of ADAM, where instead of bGLS model, KF is used.</p>
<p>The paper evaluates the model using a simulation of normal performance, tempo change and deadpan condition, and shows that the filtered state variables seems to be consistent with the nature of the pieces.</p>
<p>The model is really exciting, bridging the gap between music cognition and interactive music systems.  It will be immsensely useful for automatic accompaniment systems, beat tracking systems, or any system in which timing interaction between human musicians (or machines) are useful.</p>
<p>One issue is the evaluation, where the authors only provide the trajectory of the estimated parameters to describe why the model makes sense qualitatively.  I understand that the result seems to make sense, but I would have like to see for example comparison with other methods for parameter estimation.  For example, in all cases it takes about 20-30 onsets for the parameters to converge from the initial value.  Are these because the process noise is so small for alpha, or are these because the correction values really change after starting the performance?  </p>
<p>There are a few questions that I found might be beneficial for the authors to discuss in the paper.</p>
<ol>
<li>My understanding is that linear models for phase/period synchronization has constraints that model relationship between parameters like timekeeper and motor variance, the constraints of which necessitates the use of bGLS algorithm instead of simple regression models.   In the proposed method, however, the model is solved using KF, meaning such hard constraints cannot be handled.  Without using more elaborate variants like Unscented KF, do the filtered estimates "make sense" from music cognition perspective?  In other words, is the proposed method just a convenient state-space model for music ensemble modeling, or is it something that can provide insights to music cognition studies using ADAM?  Please discuss some limitations regarding the parameter estimates, if any.</li>
<li>Is smoothing the period/phase correction useful?  Fig. 1 seems that there is an excessive smoothing of the parameters, which hides the underlying interaction that is going on.  It would have been interesting to see how the correction parameters alpha and beta vary by changing the process noise of the corresponding parameters, or perhaps considering them independent of each other and using multiple takes of the same piece to identify the parameters.</li>
</ol>
<p>A comment</p>
<ul>
<li>In the evaluation, all of the smoothed estimates start with 0.25 which I presume is a hardcoded initial value.   I believe if the initial state covariance estimate is set to a very large value, the smoothed state estimates will have less influence on the choice of the initial value.</li>
</ul></p>
              </div>
              <hr/>


            <div> 
                <b> Review 3 </b>
                <p>This paper builds on the phase correction model and period correction model presented in [9-11], discussing how these can be optimized using Kalman filter assumptions. While a significant portion of the paper is dedicated to deriving equations, it is disappointing that the advantages of the methodology are not sufficiently demonstrated through experiments. Specifically, there is a lack of discussion on how this approach could be applied to general music scenarios. Additionally, it is unclear whether this methodology can only be applied to phase correction or period correction models, leaving the paper's significance in general synchronization contexts uncertain.</p></p>
              </div>
              <hr/>

            
            <div> 
            <b> Author description of changes: </b>
            <p>In a nutshell, the suggestions pointed out by the reviewers and the meta-reviewer were related to two main points: improve the clarity of the text and strengthen the experimental part of the paper. The first point was addressed by two modifications: writing a small sentence at the beginning of Section 4 indicating that the matrices there described aim to recover the proposed model (Eqs. 5-8) via Eqs. 9 and 10; regenerating Figure 1 with different markers, and not only different colors, to improve the readability of the paper on its black and white printed version. As to the second point (improving the experimental part of the paper), unfortunately the limitation of space does not allow us to properly discuss any other additional experiment. However, we acknowledge the issues raised by the reviewers and the meta-reviewer on the last paragraph of Section 5, indicating their resolution in future works.</p></p>
            </div>
                   
          </div>
                    
    
        </div>
      </div>
    
  </div>
  





  <script>
  document.addEventListener('DOMContentLoaded', function() {
    console.log(JSON.stringify("{&#39;id&#39;: &#39;347&#39;, &#39;session&#39;: &#39;4&#39;, &#39;position&#39;: &#39;17&#39;, &#39;forum&#39;: &#39;347&#39;, &#39;pic_id&#39;: &#39;https://drive.google.com/file/d/1Q_1EwrIcYXlMDQR39wgg7zMQEd4ECInT/view?usp=sharing&#39;, &#39;content&#39;: {&#39;title&#39;: &#39;A Kalman Filter model for synchronization in musical ensembles&#39;, &#39;paper_presentation&#39;: &#39;Remote&#39;, &#39;long_presentation&#39;: &#39;FALSE&#39;, &#39;authors&#39;: [&#39;Carvalho, Hugo T*&#39;, &#39; Li, Min Susan&#39;, &#39; Di Luca, Massimiliano&#39;, &#39; Wing, Alan M.&#39;], &#39;authors_and_affil&#39;: [&#39;Hugo T. Carvalho (Federal University of Rio de Janeiro)*&#39;, &#39; Min S. Li (University of Birmingham)&#39;, &#39; Massimiliano Di Luca (University of Birmingham)&#39;, &#39; Alan M. Wing (University of Birmingham)&#39;], &#39;keywords&#39;: [&#39;Musical features and properties&#39;, &#39;MIR tasks -&gt; alignment, synchronization, and score following; Musical features and properties -&gt; expression and performative aspects of music; Musical features and properties -&gt; rhythm, beat, tempo&#39;], &#39;abstract&#39;: &#39;The synchronization of motor responses to rhythmic auditory cues is a fundamental biological phenomenon observed across various species. While the importance of temporal alignment varies across different contexts, achieving precise temporal synchronization is a prominent goal in musical performances. Musicians often incorporate expressive timing variations, which require precise control over timing and synchronization, particularly in ensemble performance. This is crucial because both deliberate expressive nuances and accidental timing deviations can affect the overall timing of a performance. This discussion prompts the question of how musicians adjust their temporal dynamics to achieve synchronization within an ensemble. This paper introduces a novel feedback correction model based on the Kalman Filter, aimed at improving the understanding of interpersonal timing in ensemble music performances. The proposed model performs similarly to other linear correction models in the literature, with the advantage of low computational cost and good performance even in scenarios where the underlying tempo varies.&#39;, &#39;TLDR&#39;: &#39;The synchronization of motor responses to rhythmic auditory cues is a fundamental biological phenomenon observed across various species. While the importance of temporal alignment varies across different contexts, achieving precise temporal synchronization is a prominent goal in musical performances. Musicians often incorporate expressive timing variations, which require precise control over timing and synchronization, particularly in ensemble performance. This is crucial because both deliberate expressive nuances and accidental timing deviations can affect the overall timing of a performance. This discussion prompts the question of how musicians adjust their temporal dynamics to achieve synchronization within an ensemble. This paper introduces a novel feedback correction model based on the Kalman Filter, aimed at improving the understanding of interpersonal timing in ensemble music performances. The proposed model performs similarly to other linear correction models in the literature, with the advantage of low computational cost and good performance even in scenarios where the underlying tempo varies.&#39;, &#39;poster_pdf&#39;: &#39;https://drive.google.com/file/d/1PaMyuIzsGJRpviccxxaaSnHvOku7Wjg3/view?usp=sharing&#39;, &#39;session&#39;: [&#39;4&#39;], &#39;pdf_path&#39;: &#39;https://drive.google.com/file/d/1xbuQojY3c7U5aBISEmYQbcgdSrHE7IMA/view?usp=sharing&#39;, &#39;video&#39;: &#39;https://drive.google.com/file/d/1YKoc_qGkB-_kV3iYWly-RBG5QGwl3cnE/view?usp=sharing&#39;, &#39;channel_url&#39;: &#39;https://ismir2024.slack.com/archives/C07U9F9FQLF&#39;, &#39;slack_channel&#39;: &#39;p4-16-a-kalman-filter&#39;, &#39;day&#39;: &#39;2&#39;, &#39;review_1&#39;: &#39;The paper is well written and clear. I\&#39;m not an expert on how to analyze temporal alignment and synchronization between musician in an ensemble, but it was not difficult to follow the technical details, also thankfully for the clarity of the exposition. The Kalman Filter is ubiquitous and it has been proven effective also in studying how precise temporal synchronization between performers in a musical ensemble is achieved. The phase correction strength seems to be a good indicator for knowing which instruments are the leaders, and which are the followers. The results show on the Op. 74 no. 1 by Joseph Haydn are quite impressive to me. As I mentioned I\&#39;m not an expert on this very specific topic, so, unfortunately I do not know the literature, and nor the state of the art of the syncrony analysis. Give that, I red the paper with pleasure and it flows like a familiar topic to me. It would be nice to have a thorough evaluation also on other music ensemble examples. But I understand that the dataset can be a problem since this is a very specific ground truth that is not simple to obtain. Moreover, I can imagine some implication also in other MIR topics, like score followers and also generative models can use the phase correction gain to model the &#34;humanity&#34; of the timing of a computer generated music.&#39;, &#39;review_2&#39;: &#39;The paper presents a linear model for ensemble synchronization using Kalman Filter. It essentially uses time-dependent version of ADAM, where instead of bGLS model, KF is used.\n\nThe paper evaluates the model using a simulation of normal performance, tempo change and deadpan condition, and shows that the filtered state variables seems to be consistent with the nature of the pieces.\n\nThe model is really exciting, bridging the gap between music cognition and interactive music systems.  It will be immsensely useful for automatic accompaniment systems, beat tracking systems, or any system in which timing interaction between human musicians (or machines) are useful.\n\nOne issue is the evaluation, where the authors only provide the trajectory of the estimated parameters to describe why the model makes sense qualitatively.  I understand that the result seems to make sense, but I would have like to see for example comparison with other methods for parameter estimation.  For example, in all cases it takes about 20-30 onsets for the parameters to converge from the initial value.  Are these because the process noise is so small for alpha, or are these because the correction values really change after starting the performance?  \n\nThere are a few questions that I found might be beneficial for the authors to discuss in the paper.\n\n1. My understanding is that linear models for phase/period synchronization has constraints that model relationship between parameters like timekeeper and motor variance, the constraints of which necessitates the use of bGLS algorithm instead of simple regression models.   In the proposed method, however, the model is solved using KF, meaning such hard constraints cannot be handled.  Without using more elaborate variants like Unscented KF, do the filtered estimates &#34;make sense&#34; from music cognition perspective?  In other words, is the proposed method just a convenient state-space model for music ensemble modeling, or is it something that can provide insights to music cognition studies using ADAM?  Please discuss some limitations regarding the parameter estimates, if any.\n2. Is smoothing the period/phase correction useful?  Fig. 1 seems that there is an excessive smoothing of the parameters, which hides the underlying interaction that is going on.  It would have been interesting to see how the correction parameters alpha and beta vary by changing the process noise of the corresponding parameters, or perhaps considering them independent of each other and using multiple takes of the same piece to identify the parameters.\n\nA comment\n\n- In the evaluation, all of the smoothed estimates start with 0.25 which I presume is a hardcoded initial value.   I believe if the initial state covariance estimate is set to a very large value, the smoothed state estimates will have less influence on the choice of the initial value.&#39;, &#39;review_3&#39;: &#34;This paper builds on the phase correction model and period correction model presented in [9-11], discussing how these can be optimized using Kalman filter assumptions. While a significant portion of the paper is dedicated to deriving equations, it is disappointing that the advantages of the methodology are not sufficiently demonstrated through experiments. Specifically, there is a lack of discussion on how this approach could be applied to general music scenarios. Additionally, it is unclear whether this methodology can only be applied to phase correction or period correction models, leaving the paper&#39;s significance in general synchronization contexts uncertain.&#34;, &#39;meta_review&#39;: &#39;The reviewers all agree that the music syntonization problem is well formulated reconciling music cognition and the KF approach is a promising approach. Reviewer #3 emphasized that this framework has a lot of potential in other MIR tasks as well. At the same time, all reviewers pointed out that the evaluation part is weak. Specifically, the experiment was conducted on a small dataset in limited music scenarios. The results are presented qualitatively without model comparison. Nevertheless, all reviewers are generally in favor of this paper, mainly because of its potential impact on the ISMIR community.&#39;, &#39;author_changes&#39;: &#39;In a nutshell, the suggestions pointed out by the reviewers and the meta-reviewer were related to two main points: improve the clarity of the text and strengthen the experimental part of the paper. The first point was addressed by two modifications: writing a small sentence at the beginning of Section 4 indicating that the matrices there described aim to recover the proposed model (Eqs. 5-8) via Eqs. 9 and 10; regenerating Figure 1 with different markers, and not only different colors, to improve the readability of the paper on its black and white printed version. As to the second point (improving the experimental part of the paper), unfortunately the limitation of space does not allow us to properly discuss any other additional experiment. However, we acknowledge the issues raised by the reviewers and the meta-reviewer on the last paragraph of Section 5, indicating their resolution in future works.&#39;}, &#39;poster_pdf&#39;: &#39;GLTR_poster.pdf&#39;}"));
    // Ensure jQuery and Bootstrap are loaded
    if (typeof $ === 'undefined') {
      console.error('jQuery is not loaded');
      return;
    }
    
    // Initialize all tabs
    $('#posterTabs a').on('click', function (e) {
      e.preventDefault();
      $(this).tab('show');
    });
  
    // Show paper tab by default
    $('#posterTabs a[href="#paper"]').tab('show');
    MathJax.typesetPromise().then(() => {
    // modify the DOM here
        MathJax.typesetPromise();
    }).catch((err) => console.log(err.message));
  });
  </script>
  
  
    </div>
</div>



<!-- Google Analytics -->
<script
        async
        src="https://www.googletagmanager.com/gtag/js?id=UA-"
></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag("js", new Date());
  gtag("config", "UA-");
</script>

<!-- Footer -->
<footer class="footer bg-light p-4">
    <div class="container">
        <p class="float-right"><a href="#">Back to Top</a></p>
        <p class="text-center">© 2024 International Society for Music Information Retrieval</p>
    </div>
</footer>

<!-- Code for hash tags -->
<script type="text/javascript">
  $(document).ready(function () {
    if (window.location.hash !== "") {
      $(`a[href="${window.location.hash}"]`).tab("show");
    }

    $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
      const hash = $(e.target).attr("href");
      if (hash.substr(0, 1) === "#") {
        const position = $(window).scrollTop();
        window.location.replace(`#${hash.substr(1)}`);
        $(window).scrollTop(position);
      }
    });
   
  });
</script>
<!--    <script src="static/js/modules/lazyLoad.js"></script>-->

</body>
</html>