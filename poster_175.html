

<!DOCTYPE html>
<html lang="en">
<head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8"/>
    <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script
            src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
            crossorigin="anonymous"
    ></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
            integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
            integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
            crossorigin="anonymous"></script>
            <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=Gantari:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Library libs_ext --> 
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin="anonymous" referrerpolicy="no-referrer" />


    <!--    Internal Libs -->
    <script src="static/js/data/api.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY="
          crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
            href="static/css/Lato.css"
            rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet"/>
    <link
            href="static/css/Cuprum.css"
            rel="stylesheet"
    />
    <link rel="stylesheet" href="static/css/main.css"/>
<!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css"/>
    <link rel="stylesheet" href="static/css/lazy_load.css"/>
    <link rel="stylesheet" href="static/css/typeahead.css"/>

    <title>ISMIR 2024</title>
    
<meta name="citation_title" content=""/>

<meta name="citation_publication_date" content="May 2024"/>
<meta name="citation_conference_title"
      content="Ismir 2024"/>
<meta name="citation_inbook_title" content="Proceedings of the 25th International Society for Music Information Retrieval"/>
<meta name="citation_abstract" content=""/>

<meta name="citation_pdf_url" content=""/>


</head>

<body>
<!-- NAV -->

<nav
        class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
        id="main-nav"
>
    <div class="container">
        <a class="navbar-brand" href="index.html">
            <img
                    class="logo" src="static/images/ismir24_logo.svg"
                    height="auto"
            width="95px"
            />
        </a>
        
        <button
                class="navbar-toggler"
                type="button"
                data-toggle="collapse"
                data-target="#navbarNav"
                aria-controls="navbarNav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div
                class="collapse navbar-collapse text-right flex-grow-1"
                id="navbarNav"
        >
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="index.html">Schedule</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="papers.html">Papers</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="tutorials.html">Tutorials</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="lbds.html">LBDs</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="industry.html">Industry</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="jobs.html">Jobs</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>



<!-- User Overrides -->
 

<div class="container">
    <!-- Tabs -->
    <div class="tabs">
         
    </div>
    <!-- Content -->
    <div class="content">
        
<div class="pp-card m-3" style="background-color: #fff">
    <div class="card-header" style="background-color: rgba(0,0,0,0);">
        <h2 class="card-title main-title text-left" style="color: #4383EC">
            MIDI-to-Tab: Guitar Tablature Inference via Masked Language Modeling
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-left">
            
            <a href="papers.html?filter=authors&search=Andrew C Edwards (QMUL)*"
               class="text-muted"
            >Andrew C Edwards (QMUL)*</a
            >,
            
            <a href="papers.html?filter=authors&search= Xavier Riley (C4DM)"
               class="text-muted"
            > Xavier Riley (C4DM)</a
            >,
            
            <a href="papers.html?filter=authors&search= Pedro Pereira Sarmento (Centre for Digital Music)"
               class="text-muted"
            > Pedro Pereira Sarmento (Centre for Digital Music)</a
            >,
            
            <a href="papers.html?filter=authors&search= Simon Dixon (Queen Mary University of London)"
               class="text-muted"
            > Simon Dixon (Queen Mary University of London)</a
            >
            
        </h3>
        
        <div class="btn-group mb-3 mt-3">
          <a href="https://ismir2024.slack.com/archives/C07USGL5AN8" class="btn btn-primary" style="background-color: #2294e0;"><svg style="display: inline-block; width: 23px;" version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="75 75 150 150" style="enable-background:new 0 0 270 270;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
</style>
<g>
	<g>
		<path class="st0" d="M99.4,151.2c0,7.1-5.8,12.9-12.9,12.9s-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h12.9V151.2z"/>
		<path class="st0" d="M105.9,151.2c0-7.1,5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v32.3c0,7.1-5.8,12.9-12.9,12.9
			s-12.9-5.8-12.9-12.9C105.9,183.5,105.9,151.2,105.9,151.2z"/>
	</g>
	<g>
		<path class="st0" d="M118.8,99.4c-7.1,0-12.9-5.8-12.9-12.9s5.8-12.9,12.9-12.9s12.9,5.8,12.9,12.9v12.9H118.8z"/>
		<path class="st0" d="M118.8,105.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9H86.5c-7.1,0-12.9-5.8-12.9-12.9
			s5.8-12.9,12.9-12.9C86.5,105.9,118.8,105.9,118.8,105.9z"/>
	</g>
	<g>
		<path class="st0" d="M170.6,118.8c0-7.1,5.8-12.9,12.9-12.9c7.1,0,12.9,5.8,12.9,12.9s-5.8,12.9-12.9,12.9h-12.9V118.8z"/>
		<path class="st0" d="M164.1,118.8c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9V86.5c0-7.1,5.8-12.9,12.9-12.9
			c7.1,0,12.9,5.8,12.9,12.9V118.8z"/>
	</g>
	<g>
		<path class="st0" d="M151.2,170.6c7.1,0,12.9,5.8,12.9,12.9c0,7.1-5.8,12.9-12.9,12.9c-7.1,0-12.9-5.8-12.9-12.9v-12.9H151.2z"/>
		<path class="st0" d="M151.2,164.1c-7.1,0-12.9-5.8-12.9-12.9c0-7.1,5.8-12.9,12.9-12.9h32.3c7.1,0,12.9,5.8,12.9,12.9
			c0,7.1-5.8,12.9-12.9,12.9H151.2z"/>
	</g>
</g>
</svg> p2-11-midi-to-tab</a>
        </div>
        
        <p class="card-text text-left">
            <span class="">Keywords:</span>
            
            <a
                    href="papers.html?filter=keywords&search=Knowledge-driven approaches to MIR -&gt; machine learning/artificial intelligence for music; MIR tasks -&gt; music transcription and annotation; Musical features and properties -&gt; representations of music"
                    class="text-secondary text-decoration-none"
            >Knowledge-driven approaches to MIR -&gt; machine learning/artificial intelligence for music; MIR tasks -&gt; music transcription and annotation; Musical features and properties -&gt; representations of music</a
            >,
            
            <a
                    href="papers.html?filter=keywords&search=MIR fundamentals and methodology -&gt; symbolic music processing"
                    class="text-secondary text-decoration-none"
            >MIR fundamentals and methodology -&gt; symbolic music processing</a
            >
            
        </p>
    </div>

</div>

<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <span class="font-weight-bold">Abstract:</span>
                <p>Guitar tablatures enrich the structure of music notation by assigning each note to a string and fret of a guitar in a particular tuning, defining precisely where to play the note on the instrument. The problem of generating tablature from a symbolic music representation involves inferring this string and fret assignment per note across an entire composition or performance. On the guitar, multiple string-fret assignments are possible for each pitch, which leads to a large combinatorial space that prevents exhaustive search approaches. Most modern methods use constraint-based dynamic programming approaches to minimize some cost function (e.g. hand position movement). In this work, we introduce a novel deep learning solution to symbolic guitar tablature estimation. We train an encoder-decoder Transformer model in a masked language modeling paradigm to assign notes to strings. The model is first pre-trained on DadaGP, a dataset of over 25K tablatures, and then fine-tuned on a curated set of professionally transcribed guitar performances. Given the subjective nature of assessing tablature quality, we conduct a user study amongst guitarists, wherein we ask participants to rate the playability of multiple versions of tablature for the same four-bar excerpt. The results indicate our system significantly outperforms competing algorithms.</p>
            </div>
        </div>
        <p></p>
    </div>
</div>


  
  <div class="text-center">
    <ul class="nav nav-tabs" id="posterTabs" role="tablist">
      <li class="nav-item" role="presentation">
        <a class="nav-link active" id="paper-tab" data-toggle="tab" href="#paper" role="tab" aria-controls="paper" aria-selected="true">Paper</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="poster-tab" data-toggle="tab" href="#poster" role="tab" aria-controls="poster" aria-selected="false">Poster</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="video-tab" data-toggle="tab" href="#video" role="tab" aria-controls="video" aria-selected="false">Video</a>
      </li>
      <li class="nav-item" role="presentation">
        <a class="nav-link" id="Reviews-tab" data-toggle="tab" href="#Reviews" role="tab" aria-controls="Reviews" aria-selected="false">Reviews</a>
      </li>
    </ul>
  </div>
  

  <div class="tab-content" id="posterTabsContent">
    <div class="tab-pane fade show active" id="paper" role="tabpanel" aria-labelledby="paper-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/1dA3AfAQem0BFPcvtKOIvP1gPe1LLphtb/preview" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="poster" role="tabpanel" aria-labelledby="poster-tab">
      
      <div style="height: 80vh;">
        <iframe src="https://drive.google.com/file/d/1wNvHcqpvSlqibYDq1Ww4DIltYIjRvpXW/preview?usp=drive_link" 
                width="100%" 
                height="100%" 
                frameborder="0"
                allow="autoplay"></iframe>
      </div>
      
    </div>
  
    <div class="tab-pane fade" id="video" role="tabpanel" aria-labelledby="video-tab">
      
      <div class="text-center">
        <div class="embed-responsive embed-responsive-16by9">
          <iframe class="embed-responsive-item"           
                  src="https://drive.google.com/file/d/1eKOb0fTCyui8Hwi6WBoAsZZqbSC-2g5G/preview?usp=drive_link" 
                  frameborder="0" 
                  allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" 
                  allowfullscreen></iframe>
        </div>
      </div>
      
    </div>
    <div class="tab-pane fade" id="Reviews" role="tabpanel" aria-labelledby="Reviews-tab">
      <div class="pp-card m-3">
        <div class="card-body">
          <h5 class="card-title">
            Reviews
          </h5>
          <div class="card-text">
            
            <div> 
                <b> Meta Review </b> 
                <p> <p>This paper presents a deep learning method (Transformer trained with masked language modeling) for MIDI-to-tablature conversion, which achieves better performance than existing methods.</p>
<p>While all three reviews and the independent meta-review liked the main idea and contributions of this work, they also pointed out a number of issues. Please read all the reviews to see the detailed comments. Specifically, the paper needs to clarify many important details including the network architecture, test data, the post-processing procedure, the metric on agreement between system output and human annotation, subjective evaluation instructions, and some analyses of experimental results. </p>
<p>Based on the reviews and discussions, the final recommendation is "Accept".</p></p>
              </div>
              <hr/>
        
            <div>
                <b> Review 1 </b>
                <p class="card-text"><p>This article adresses the task of assigning realistic guitar string/fret positions to the notes of a MIDI content, which is here judiciously simplified as a string assignment problem. This task is well known in the community, sometimes under the term of "fingering" problem. The probem is here addressed with a Transformer, trained with a masking process on the string information.</p>
<p>The paper is well written and clearly structured. The approach is promising, but some points are still to be clarified, in particular in the evaluation.</p>
<p>Regarding the title: because "Tablature" commonly refers to a particular type of musical score, the reader might wrongly think that the term "tablature inference" refers to "tablature generation" (analogous to "score generation"). It might be good therefore to clarify the title.</p>
<p>The quintile approach judiciously allows to provide some context regarding the data that are being labelled by the model. It although raises the question of the inference of the first ten tokens, which can not benefit from any past context. How does the model handle this ? It seems important as it will arguably impact the predictions for the following quantiles and so on.</p>
<p>In section 4.4, it would be more clear to state, within the third sentence, the proportion of unplayable predictions (I believe that it is 0,53%, as said in the end of the section, but I think the reader will wonder that number as soon as the problem is stated). Although the introduction of 4.4 is clear, the description of the algorithm lacks details. Are we talking about simultaneous notes ? or notes in a 10-notes window ? In 3.b, how could the center note have a fret value higher than MAX_DEVIATION (which is a fret interval, not a fret number) ?</p>
<p>The number of tab in the fine-tuning set should be indicated.</p>
<p>I don't understand why the evaluation is on the 9 tablatures only. The (large) size of the datasets used in this work arguably enables a much larger evaluation.</p>
<p>It is great to compare the results of the proposed approach with functionnalities of existing (and well-used) software, but I regret the lack of comparison with SOTA approaches that have been published, although not necessary implemented in any software. I suspect that GuitarPro, MuseScore and TuxGuitar might not have considered the performance of this functionality as a priority (given that these software are primarily thought for score/tab visualisation/playback/writing rather than for tab midi-to-tab transcription) and might be far from sota, and rather be an "easy" baseline.</p>
<p>I don't understand why a mistake like Fig.5 (right) could occur given that the post-processing algo (4.4) is supposed to avoid unplayable content. To disambiguate, it could be interesting to illustrate unplayability (of Section 4.4) with a concrete example.</p>
<p>The network architecture is poorly described (2 lines). Why is the hidden size 384-dimensional ? What is the input dimension ? I guess it must be the size of the token alphabet, so what is this size ?</p>
<p>The second sentence of Section 4.3 seems of strong importance, but it is hardly understandable. I think that the pedagogy of the paper could be improved by illustrating the BART architecture for the reader unfamiliar with the original publication.</p></p>
              </div>
            </div>
            <hr/>

            <div> 
                <b> Review 2 </b>
                <p>This paper is a nice contribution to the field of automatic transcription to tablature. It summarises prior art, uses a sensible corpus and evaluates in good ways. 
More explicit reflection on the problems of representation might be nice here - without temporal information ro representations of simultaneity in the input (am I understanding that correctly?), it's not that surprising that physically awkward or impossible results would come out. The example in figure 5 (along with the graph in figure 4) shows this well -- each decision taken individually seems sensible, except for the chords. This is especially true if the sequence of input notes had the B2 as the second note. Where the order of notes in a chord affects the result, that's a suggestion that the model is sub optimal...</p></p>
              </div>
              <hr/>


            <div> 
                <b> Review 3 </b>
                <p>The paper presents a simple solution for guitar tablature generation from MIDI in which an encoder-decoder Transformer is trained using a masked language modeling supervision scheme (masking string tokens) to assign notes to strings. The inference is done in an autoregressive fashion and some post-processing heuristics are applied to the output of the model. The model is trained on a large dataset of crowdsourced tablatures and then fine-tuned on a small set of professionally transcribed performances. </p>
<p>It is not clear why the tokenization is deemed as novel in the introduction section of the paper. I understand that the model uses an existing tokenizer (MidiTok) and that the string is encoded with the track token. I encourage the authors to provide more information on why the tokenization is novel. </p>
<p>Experiments compare the proposed model with a commercial system and two open-source software implementations capable of producing tablatures from score or MIDI. Given the challenges involved in assessing the quality of tablatures, the experiments include a user study. The paper provides an interesting discussion of the results and limitations of the proposed approach and suggests various ideas for future research. </p>
<p>The manuscript is well-written and organized, and overall, the paper makes a good contribution to ISMIR. </p>
<p>The supplementary material includes a subset of the codebase, but the manuscript does not indicate whether the code or models will be available. It would be very important to clarify whether the code and model will be available for reproducibility. </p>
<p>Minor corrections</p>
<p>Line 43 - References to existing publications should be added here. </p>
<p>Line 56 - Please reconsider the novelty of the tokenization.</p>
<p>Section 5.1 - There is no reference in the text to Figure 4. Please link the figure to the text describing the evaluatiuon on the strech across the chords.</p></p>
              </div>
              <hr/>

            
            <div> 
            <b> Author description of changes: </b>
            <ol>
<li>We clarify the inference mechanism and illustrate why it reduces the asymmetry between inference and training by having higher confidence / probability values for past values input to the decoder.</li>
<li>We clarify the notion of center note and the choice of a moving window of 11 notes in the post-processing heuristics.</li>
<li>We add more information about the finetuning (train, test, and validation), instead of relying on the reference to Riley et al. [12]</li>
<li>We clarified that subjects were instructed to ignore the difficulty of excerpts in the user study.</li>
<li>We lessen the claim that the system as-is could be used as a generic arranger (regardless of the provenance of the MIDI data) and instead that it can be viewed as a guitar tablature arranging system.</li>
<li>We describe that the BART architecture hyperparameters are not finetuned at all and are simply half the size of the BART base model.</li>
<li>The second sentence of Section 4.3 is rewritten to be more clear.</li>
</ol></p>
            </div>
                   
          </div>
                    
    
        </div>
      </div>
    
  </div>
  





  <script>
  document.addEventListener('DOMContentLoaded', function() {
    console.log(JSON.stringify("{&#39;id&#39;: &#39;175&#39;, &#39;session&#39;: &#39;2&#39;, &#39;position&#39;: &#39;12&#39;, &#39;forum&#39;: &#39;175&#39;, &#39;pic_id&#39;: &#39;https://drive.google.com/file/d/1_0gL0ENfndsCMpHoxvaVD8r6lmOOz4xA/view?usp=drive_link&#39;, &#39;content&#39;: {&#39;title&#39;: &#39;MIDI-to-Tab: Guitar Tablature Inference via Masked Language Modeling&#39;, &#39;paper_presentation&#39;: &#39;San Francisco&#39;, &#39;long_presentation&#39;: &#39;FALSE&#39;, &#39;authors&#39;: [&#39;Edwards, Andrew C*&#39;, &#39; Riley, Xavier&#39;, &#39; Sarmento, Pedro Pereira&#39;, &#39; Dixon, Simon&#39;], &#39;authors_and_affil&#39;: [&#39;Andrew C Edwards (QMUL)*&#39;, &#39; Xavier Riley (C4DM)&#39;, &#39; Pedro Pereira Sarmento (Centre for Digital Music)&#39;, &#39; Simon Dixon (Queen Mary University of London)&#39;], &#39;keywords&#39;: [&#39;Knowledge-driven approaches to MIR -&gt; machine learning/artificial intelligence for music; MIR tasks -&gt; music transcription and annotation; Musical features and properties -&gt; representations of music&#39;, &#39;MIR fundamentals and methodology -&gt; symbolic music processing&#39;], &#39;abstract&#39;: &#39;Guitar tablatures enrich the structure of music notation by assigning each note to a string and fret of a guitar in a particular tuning, defining precisely where to play the note on the instrument. The problem of generating tablature from a symbolic music representation involves inferring this string and fret assignment per note across an entire composition or performance. On the guitar, multiple string-fret assignments are possible for each pitch, which leads to a large combinatorial space that prevents exhaustive search approaches. Most modern methods use constraint-based dynamic programming approaches to minimize some cost function (e.g. hand position movement). In this work, we introduce a novel deep learning solution to symbolic guitar tablature estimation. We train an encoder-decoder Transformer model in a masked language modeling paradigm to assign notes to strings. The model is first pre-trained on DadaGP, a dataset of over 25K tablatures, and then fine-tuned on a curated set of professionally transcribed guitar performances. Given the subjective nature of assessing tablature quality, we conduct a user study amongst guitarists, wherein we ask participants to rate the playability of multiple versions of tablature for the same four-bar excerpt. The results indicate our system significantly outperforms competing algorithms.&#39;, &#39;TLDR&#39;: &#39;Guitar tablatures enrich the structure of music notation by assigning each note to a string and fret of a guitar in a particular tuning, defining precisely where to play the note on the instrument. The problem of generating tablature from a symbolic music representation involves inferring this string and fret assignment per note across an entire composition or performance. On the guitar, multiple string-fret assignments are possible for each pitch, which leads to a large combinatorial space that prevents exhaustive search approaches. Most modern methods use constraint-based dynamic programming approaches to minimize some cost function (e.g. hand position movement). In this work, we introduce a novel deep learning solution to symbolic guitar tablature estimation. We train an encoder-decoder Transformer model in a masked language modeling paradigm to assign notes to strings. The model is first pre-trained on DadaGP, a dataset of over 25K tablatures, and then fine-tuned on a curated set of professionally transcribed guitar performances. Given the subjective nature of assessing tablature quality, we conduct a user study amongst guitarists, wherein we ask participants to rate the playability of multiple versions of tablature for the same four-bar excerpt. The results indicate our system significantly outperforms competing algorithms.&#39;, &#39;poster_pdf&#39;: &#39;https://drive.google.com/file/d/1wNvHcqpvSlqibYDq1Ww4DIltYIjRvpXW/view?usp=drive_link&#39;, &#39;session&#39;: [&#39;2&#39;], &#39;pdf_path&#39;: &#39;https://drive.google.com/file/d/1dA3AfAQem0BFPcvtKOIvP1gPe1LLphtb/view?usp=sharing&#39;, &#39;video&#39;: &#39;https://drive.google.com/file/d/1eKOb0fTCyui8Hwi6WBoAsZZqbSC-2g5G/view?usp=drive_link&#39;, &#39;channel_url&#39;: &#39;https://ismir2024.slack.com/archives/C07USGL5AN8&#39;, &#39;slack_channel&#39;: &#39;p2-11-midi-to-tab&#39;, &#39;day&#39;: &#39;1&#39;, &#39;review_1&#39;: &#39;This article adresses the task of assigning realistic guitar string/fret positions to the notes of a MIDI content, which is here judiciously simplified as a string assignment problem. This task is well known in the community, sometimes under the term of &#34;fingering&#34; problem. The probem is here addressed with a Transformer, trained with a masking process on the string information.\n\nThe paper is well written and clearly structured. The approach is promising, but some points are still to be clarified, in particular in the evaluation.\n\nRegarding the title: because &#34;Tablature&#34; commonly refers to a particular type of musical score, the reader might wrongly think that the term &#34;tablature inference&#34; refers to &#34;tablature generation&#34; (analogous to &#34;score generation&#34;). It might be good therefore to clarify the title.\n\nThe quintile approach judiciously allows to provide some context regarding the data that are being labelled by the model. It although raises the question of the inference of the first ten tokens, which can not benefit from any past context. How does the model handle this ? It seems important as it will arguably impact the predictions for the following quantiles and so on.\n\nIn section 4.4, it would be more clear to state, within the third sentence, the proportion of unplayable predictions (I believe that it is 0,53%, as said in the end of the section, but I think the reader will wonder that number as soon as the problem is stated). Although the introduction of 4.4 is clear, the description of the algorithm lacks details. Are we talking about simultaneous notes ? or notes in a 10-notes window ? In 3.b, how could the center note have a fret value higher than MAX_DEVIATION (which is a fret interval, not a fret number) ?\n\nThe number of tab in the fine-tuning set should be indicated.\n\nI don\&#39;t understand why the evaluation is on the 9 tablatures only. The (large) size of the datasets used in this work arguably enables a much larger evaluation.\n\nIt is great to compare the results of the proposed approach with functionnalities of existing (and well-used) software, but I regret the lack of comparison with SOTA approaches that have been published, although not necessary implemented in any software. I suspect that GuitarPro, MuseScore and TuxGuitar might not have considered the performance of this functionality as a priority (given that these software are primarily thought for score/tab visualisation/playback/writing rather than for tab midi-to-tab transcription) and might be far from sota, and rather be an &#34;easy&#34; baseline.\n\nI don\&#39;t understand why a mistake like Fig.5 (right) could occur given that the post-processing algo (4.4) is supposed to avoid unplayable content. To disambiguate, it could be interesting to illustrate unplayability (of Section 4.4) with a concrete example.\n\nThe network architecture is poorly described (2 lines). Why is the hidden size 384-dimensional ? What is the input dimension ? I guess it must be the size of the token alphabet, so what is this size ?\n\nThe second sentence of Section 4.3 seems of strong importance, but it is hardly understandable. I think that the pedagogy of the paper could be improved by illustrating the BART architecture for the reader unfamiliar with the original publication.&#39;, &#39;review_2&#39;: &#34;This paper is a nice contribution to the field of automatic transcription to tablature. It summarises prior art, uses a sensible corpus and evaluates in good ways. \nMore explicit reflection on the problems of representation might be nice here - without temporal information ro representations of simultaneity in the input (am I understanding that correctly?), it&#39;s not that surprising that physically awkward or impossible results would come out. The example in figure 5 (along with the graph in figure 4) shows this well -- each decision taken individually seems sensible, except for the chords. This is especially true if the sequence of input notes had the B2 as the second note. Where the order of notes in a chord affects the result, that&#39;s a suggestion that the model is sub optimal...&#34;, &#39;review_3&#39;: &#39;The paper presents a simple solution for guitar tablature generation from MIDI in which an encoder-decoder Transformer is trained using a masked language modeling supervision scheme (masking string tokens) to assign notes to strings. The inference is done in an autoregressive fashion and some post-processing heuristics are applied to the output of the model. The model is trained on a large dataset of crowdsourced tablatures and then fine-tuned on a small set of professionally transcribed performances. \n\nIt is not clear why the tokenization is deemed as novel in the introduction section of the paper. I understand that the model uses an existing tokenizer (MidiTok) and that the string is encoded with the track token. I encourage the authors to provide more information on why the tokenization is novel. \n\nExperiments compare the proposed model with a commercial system and two open-source software implementations capable of producing tablatures from score or MIDI. Given the challenges involved in assessing the quality of tablatures, the experiments include a user study. The paper provides an interesting discussion of the results and limitations of the proposed approach and suggests various ideas for future research. \n\nThe manuscript is well-written and organized, and overall, the paper makes a good contribution to ISMIR. \n\nThe supplementary material includes a subset of the codebase, but the manuscript does not indicate whether the code or models will be available. It would be very important to clarify whether the code and model will be available for reproducibility. \n\nMinor corrections\n\nLine 43 - References to existing publications should be added here. \n\nLine 56 - Please reconsider the novelty of the tokenization.\n\nSection 5.1 - There is no reference in the text to Figure 4. Please link the figure to the text describing the evaluatiuon on the strech across the chords.\n&#39;, &#39;meta_review&#39;: &#39;This paper presents a deep learning method (Transformer trained with masked language modeling) for MIDI-to-tablature conversion, which achieves better performance than existing methods.\n\nWhile all three reviews and the independent meta-review liked the main idea and contributions of this work, they also pointed out a number of issues. Please read all the reviews to see the detailed comments. Specifically, the paper needs to clarify many important details including the network architecture, test data, the post-processing procedure, the metric on agreement between system output and human annotation, subjective evaluation instructions, and some analyses of experimental results. \n\nBased on the reviews and discussions, the final recommendation is &#34;Accept&#34;.&#39;, &#39;author_changes&#39;: &#39;1. We clarify the inference mechanism and illustrate why it reduces the asymmetry between inference and training by having higher confidence / probability values for past values input to the decoder.\n2. We clarify the notion of center note and the choice of a moving window of 11 notes in the post-processing heuristics.\n3. We add more information about the finetuning (train, test, and validation), instead of relying on the reference to Riley et al. [12]\n4. We clarified that subjects were instructed to ignore the difficulty of excerpts in the user study.\n5. We lessen the claim that the system as-is could be used as a generic arranger (regardless of the provenance of the MIDI data) and instead that it can be viewed as a guitar tablature arranging system.\n6. We describe that the BART architecture hyperparameters are not finetuned at all and are simply half the size of the BART base model.\n7. The second sentence of Section 4.3 is rewritten to be more clear.&#39;}, &#39;poster_pdf&#39;: &#39;GLTR_poster.pdf&#39;}"));
    // Ensure jQuery and Bootstrap are loaded
    if (typeof $ === 'undefined') {
      console.error('jQuery is not loaded');
      return;
    }
    
    // Initialize all tabs
    $('#posterTabs a').on('click', function (e) {
      e.preventDefault();
      $(this).tab('show');
    });
  
    // Show paper tab by default
    $('#posterTabs a[href="#paper"]').tab('show');
    MathJax.typesetPromise().then(() => {
    // modify the DOM here
        MathJax.typesetPromise();
    }).catch((err) => console.log(err.message));
  });
  </script>
  
  
    </div>
</div>



<!-- Google Analytics -->
<script
        async
        src="https://www.googletagmanager.com/gtag/js?id=UA-"
></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag("js", new Date());
  gtag("config", "UA-");
</script>

<!-- Footer -->
<footer class="footer bg-light p-4">
    <div class="container">
        <p class="float-right"><a href="#">Back to Top</a></p>
        <p class="text-center">© 2024 International Society for Music Information Retrieval</p>
    </div>
</footer>

<!-- Code for hash tags -->
<script type="text/javascript">
  $(document).ready(function () {
    if (window.location.hash !== "") {
      $(`a[href="${window.location.hash}"]`).tab("show");
    }

    $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
      const hash = $(e.target).attr("href");
      if (hash.substr(0, 1) === "#") {
        const position = $(window).scrollTop();
        window.location.replace(`#${hash.substr(1)}`);
        $(window).scrollTop(position);
      }
    });
   
  });
</script>
<!--    <script src="static/js/modules/lazyLoad.js"></script>-->

</body>
</html>